{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1 What is hypothesis testing in statistics?\n",
        "\n",
        "Answer: Hypothesis testing is a statistical method used to make inferences or decisions about a population parameter based on sample data. It involves formulating a null hypothesis (H₀) and an alternative hypothesis (Hₐ), and then using data to decide whether to reject H₀ in favor of Hₐ.\n",
        "\n",
        "2 What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "\n",
        "Answer: The null hypothesis (H₀) is a statement of no effect or no difference, acting as the baseline assumption. The alternative hypothesis (Hₐ) is what you want to test for—it represents a new effect, difference, or relationship. Rejecting H₀ provides evidence in favor of Hₐ.\n",
        "\n",
        "3 What is the significance level in hypothesis testing, and why is it important?\n",
        "\n",
        "Answer: The significance level (often denoted as α, e.g., 0.05) is the threshold probability for rejecting the null hypothesis. It quantifies the risk of committing a Type I error (rejecting a true null hypothesis) and is crucial for controlling false positives.\n",
        "\n",
        "4 What does a P-value represent in hypothesis testing?\n",
        "\n",
        "Answer: The P-value is the probability of obtaining a test statistic at least as extreme as the one observed, assuming the null hypothesis is true. It reflects the strength of the evidence against H₀.\n",
        "\n",
        "5 How do you interpret the P-value in hypothesis testing?\n",
        "\n",
        "Answer: A small P-value (typically < α) indicates strong evidence against the null hypothesis, leading to its rejection. Conversely, a large P-value suggests insufficient evidence to reject H₀.\n",
        "\n",
        "6 What are Type I and Type II errors in hypothesis testing?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Type I error: Incorrectly rejecting a true null hypothesis (false positive).\n",
        "Type II error: Failing to reject a false null hypothesis (false negative).\n",
        "\n",
        "7What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "\n",
        "Answer:\n",
        "\n",
        "One-tailed test: Tests for an effect in a single direction (e.g., Hₐ: parameter > value or parameter < value).\n",
        "Two-tailed test: Tests for an effect in both directions (Hₐ: parameter ≠ value).\n",
        "\n",
        "8 What is the Z-test, and when is it used in hypothesis testing?\n",
        "\n",
        "Answer: A Z-test is used when the sample size is large (or the population standard deviation is known) to test hypotheses about the population mean or proportion based on the standard normal distribution.\n",
        "\n",
        "9 How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "\n",
        "Answer: The Z-score is calculated using\n",
        "\n",
        "Z\n",
        "=\n",
        "x\n",
        "ˉ\n",
        "−\n",
        "μ\n",
        "σ\n",
        "/\n",
        "n\n",
        ",\n",
        "Z=\n",
        "σ/\n",
        "n\n",
        "​\n",
        "\n",
        "x\n",
        "ˉ\n",
        " −μ\n",
        "​\n",
        " ,\n",
        "\n",
        "\n",
        "where $\\bar{x}$ is the sample mean, $\\mu$ is the population mean, $\\sigma$ is the standard deviation, and $n$ is the sample size. It represents how many standard deviations the sample mean is away from the population mean.\n",
        "\n",
        "10 What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "\n",
        "Answer: The T-distribution is similar to the normal distribution but with heavier tails and is used when the sample size is small and/or the population standard deviation is unknown. As sample size increases, it converges to the normal distribution.\n",
        "\n",
        "11 What is the difference between a Z-test and a T-test?\n",
        "\n",
        "Answer: A Z-test uses the standard normal distribution and is applied when the population variance is known or the sample size is large. A T-test uses the T-distribution and is preferred when the population variance is unknown and the sample size is small.\n",
        "\n",
        "12 What is the T-test, and how is it used in hypothesis testing?\n",
        "\n",
        "Answer: A T-test is a procedure for testing hypotheses about the mean when the population variance is unknown. There are several types, including one-sample, independent, and paired T-tests, to compare means under different scenarios.\n",
        "\n",
        "13 What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "\n",
        "Answer: Both tests compare sample statistics to population parameters but differ mainly in assumptions about variance and sample size. For large samples or known variance, the T-test becomes equivalent to the Z-test.\n",
        "\n",
        "14 What is a confidence interval, and how is it used to interpret statistical results?\n",
        "\n",
        "Answer: A confidence interval provides a range of plausible values for a population parameter. It is interpreted as, “we are X% confident that the true parameter lies within this interval”—offering both an estimate and its uncertainty.\n",
        "\n",
        "15 What is the margin of error, and how does it affect the confidence interval?\n",
        "\n",
        "Answer: The margin of error is half the width of a confidence interval. It reflects the maximum expected difference between the sample estimate and the true population parameter. A smaller margin yields a narrower, more precise interval.\n",
        "\n",
        "16 How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "\n",
        "Answer: Bayes’ Theorem updates prior beliefs with new evidence. It calculates the posterior probability of a hypothesis given observed data, and is significant in Bayesian inference where probabilities are revised as more information becomes available.\n",
        "\n",
        "17 What is the Chi-square distribution, and when is it used?\n",
        "\n",
        "Answer: The Chi-square distribution is used to assess variability or goodness of fit. It is commonly used in tests for independence in contingency tables and for determining if an observed frequency distribution differs from a theoretical one.\n",
        "\n",
        "18 What is the Chi-square goodness of fit test, and how is it applied?\n",
        "\n",
        "Answer: The Chi-square goodness of fit test compares observed frequencies to expected frequencies under a specified distribution. A significant test result suggests that the observed data do not follow the expected distribution.\n",
        "\n",
        "19 What is the F-distribution, and when is it used in hypothesis testing?\n",
        "\n",
        "Answer: The F-distribution is used in the analysis of variance (ANOVA) and in tests comparing two variances. It arises as the ratio of two scaled Chi-square distributed variables.\n",
        "\n",
        "20 What is an ANOVA test, and what are its assumptions?\n",
        "\n",
        "Answer: ANOVA (Analysis of Variance) tests the hypothesis that the means of multiple groups are equal. Its main assumptions include independence of observations, normality within groups, and homogeneity of variances across groups.\n",
        "\n",
        "21 What are the different types of ANOVA tests?\n",
        "\n",
        "Answer: Common forms of ANOVA include:\n",
        "\n",
        "One-way ANOVA: Compares means across a single factor with multiple groups.\n",
        "Two-way ANOVA: Evaluates the effect of two independent factors and their interaction.\n",
        "Repeated Measures ANOVA: Used when the same subjects are measured under different conditions.\n",
        "\n",
        "22 What is the F-test, and how does it relate to hypothesis testing?\n",
        "\n",
        "Answer: An F-test is used to compare two variances by calculating the ratio of the variances and comparing it to the F-distribution. It is integral to ANOVA, where the F-test determines whether group means are significantly different."
      ],
      "metadata": {
        "id": "7Ox44Pr6BP4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "29YwB88jCWVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Part - 1"
      ],
      "metadata": {
        "id": "sALvDQiRKSXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oMtKJi8AKWhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Write a Python program to generate a random variable and display its value\n",
        "\n",
        "import random\n",
        "\n",
        "random_variable = random.randint(1, 100) # Generates a random integer between 1 and 100\n",
        "print(\"Random variable value:\", random_variable)"
      ],
      "metadata": {
        "id": "GJgWcSy6Dfpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Generate a discrete uniform distribution using Python and plot the probability mass function (PMF)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the range of possible outcomes\n",
        "low = 1\n",
        "high = 10\n",
        "outcomes = np.arange(low, high + 1)\n",
        "\n",
        "# Create a discrete uniform distribution\n",
        "# For a discrete uniform distribution, the probability of each outcome is equal\n",
        "n_outcomes = len(outcomes)\n",
        "probabilities = np.full(n_outcomes, 1 / n_outcomes)\n",
        "\n",
        "# Plot the PMF\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(outcomes, probabilities, color='skyblue')\n",
        "plt.xlabel('Outcome')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Probability Mass Function of a Discrete Uniform Distribution')\n",
        "plt.xticks(outcomes)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AJXbsykbDp9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution\n",
        "\n",
        "def bernoulli_pdf(k, p):\n",
        "  \"\"\"\n",
        "    Calculates the probability distribution function (PDF) of a Bernoulli distribution.\n",
        "\n",
        "    Args:\n",
        "      k: The outcome (0 for failure, 1 for success).\n",
        "      p: The probability of success (between 0 and 1).\n",
        "\n",
        "    Returns:\n",
        "      The probability of the given outcome k.\n",
        "    \"\"\"\n",
        "  if k == 1:\n",
        "    return p\n",
        "  elif k == 0:\n",
        "    return 1 - p\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "Cc8wjNkzD2Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Simulate the binomial distribution\n",
        "n = 10\n",
        "p = 0.5\n",
        "size = 1000  # Number of simulations\n",
        "binomial_samples = np.random.binomial(n, p, size)\n",
        "\n",
        "# Plot the histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(binomial_samples, bins=np.arange(-0.5, n + 1.5, 1), rwidth=0.8, density=True, color='salmon', edgecolor='black')\n",
        "plt.xlabel('Number of Successes')\n",
        "plt.ylabel('Probability')\n",
        "plt.title(f'Histogram of Binomial Distribution (n={n}, p={p})')\n",
        "plt.xticks(np.arange(0, n + 1, 1))\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8sWbqj7iEAQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Create a Poisson distribution and visualize it using Python\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# 5 Create a Poisson distribution and visualize it using Python\n",
        "\n",
        "# Define the average rate (lambda)\n",
        "lambda_val = 3  # Example average rate of events\n",
        "\n",
        "# Generate random samples from the Poisson distribution\n",
        "size = 1000  # Number of samples\n",
        "poisson_samples = np.random.poisson(lambda_val, size)\n",
        "\n",
        "# Plot the histogram of the samples\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(poisson_samples, bins=np.arange(-0.5, max(poisson_samples) + 1.5, 1), rwidth=0.8, density=True, color='lightgreen', edgecolor='black')\n",
        "plt.xlabel('Number of Events')\n",
        "plt.ylabel('Probability')\n",
        "plt.title(f'Histogram of Poisson Distribution (λ={lambda_val})')\n",
        "plt.xticks(np.arange(0, max(poisson_samples) + 1, 1))\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZA8u-VPAEIny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6 Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete uniform distribution\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Calculate the cumulative distribution function (CDF)\n",
        "# The CDF at a point x is the probability that the random variable is less than or equal to x\n",
        "cdf = np.cumsum(probabilities)\n",
        "\n",
        "# Plot the CDF\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.step(outcomes, cdf, where='post', color='purple')\n",
        "plt.xlabel('Outcome')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.title('Cumulative Distribution Function of a Discrete Uniform Distribution')\n",
        "plt.xticks(outcomes)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gjxCDGOKEeoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7 Generate a continuous uniform distribution using NumPy and visualize it\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Define the parameters of the continuous uniform distribution\n",
        "low = 0  # Lower bound\n",
        "high = 10 # Upper bound\n",
        "\n",
        "# Generate random samples from the continuous uniform distribution\n",
        "size = 1000 # Number of samples\n",
        "uniform_samples = np.random.uniform(low, high, size)\n",
        "\n",
        "# Plot the histogram of the samples\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(uniform_samples, bins=50, density=True, color='orange', edgecolor='black')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.title(f'Histogram of Continuous Uniform Distribution (low={low}, high={high})')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EhWc8m8BEwJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8 Simulate data from a normal distribution and plot its histogram\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Define the parameters for the normal distribution\n",
        "mu = 0  # Mean\n",
        "sigma = 1 # Standard deviation\n",
        "\n",
        "# Simulate data from the normal distribution\n",
        "size = 1000  # Number of samples\n",
        "normal_samples = np.random.normal(mu, sigma, size)\n",
        "\n",
        "# Plot the histogram of the samples\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(normal_samples, bins=50, density=True, color='lightblue', edgecolor='black')\n",
        "\n",
        "# Plot the PDF of the normal distribution for comparison\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "p = (1/(sigma*np.sqrt(2*np.pi)))*np.exp(-((x-mu)**2)/(2*sigma**2))\n",
        "plt.plot(x, p, 'k', linewidth=2)\n",
        "\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.title(f'Histogram of Normal Distribution (μ={mu}, σ={sigma})')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EPV2Xt-hE5xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9  Write a Python function to calculate Z-scores from a dataset and plot them\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def calculate_and_plot_zscores(data):\n",
        "  \"\"\"\n",
        "  Calculates Z-scores for a dataset and plots their histogram.\n",
        "\n",
        "  Args:\n",
        "    data: A list or NumPy array of numerical data.\n",
        "  \"\"\"\n",
        "  # Calculate the mean and standard deviation\n",
        "  mean = np.mean(data)\n",
        "  std_dev = np.std(data)\n",
        "\n",
        "  # Calculate Z-scores\n",
        "  z_scores = [(x - mean) / std_dev for x in data]\n",
        "\n",
        "  # Plot the histogram of Z-scores\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.hist(z_scores, bins=50, density=True, color='gold', edgecolor='black')\n",
        "\n",
        "  # Plot the PDF of the standard normal distribution (mean=0, std=1) for comparison\n",
        "  xmin, xmax = plt.xlim()\n",
        "  x = np.linspace(xmin, xmax, 100)\n",
        "  p = (1 / np.sqrt(2 * np.pi)) * np.exp(-(x ** 2) / 2)\n",
        "  plt.plot(x, p, 'k', linewidth=2)\n",
        "\n",
        "  plt.xlabel('Z-score')\n",
        "  plt.ylabel('Density')\n",
        "  plt.title('Histogram of Z-scores and Standard Normal Distribution PDF')\n",
        "  plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "  plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'normal_samples' was generated in the previous cell\n",
        "calculate_and_plot_zscores(normal_samples)"
      ],
      "metadata": {
        "id": "gQM5p8mHFGA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Central Limit Theorem (CLT) Implementation with a Non-Normal Distribution (e.g., Exponential)\n",
        "\n",
        "# Define the parameters of the exponential distribution\n",
        "lambda_exp = 0.5 # Rate parameter\n",
        "\n",
        "# Define the parameters for the CLT simulation\n",
        "sample_size = 30 # Size of each sample\n",
        "num_samples = 1000 # Number of samples to draw\n",
        "\n",
        "# Generate samples from the exponential distribution and calculate their means\n",
        "sample_means = []\n",
        "for _ in range(num_samples):\n",
        "  exponential_samples = np.random.exponential(scale=1/lambda_exp, size=sample_size)\n",
        "  sample_means.append(np.mean(exponential_samples))\n",
        "\n",
        "# Plot the histogram of the sample means\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(sample_means, bins=50, density=True, color='violet', edgecolor='black')\n",
        "\n",
        "# Plot the theoretical normal distribution based on the expected mean and standard deviation of the sample means\n",
        "# For exponential distribution, expected value (mu) = 1/lambda, variance = 1/lambda^2\n",
        "# According to CLT, mean of sample means approaches population mean (1/lambda)\n",
        "# According to CLT, standard deviation of sample means approaches population standard deviation / sqrt(sample_size)\n",
        "# Population standard deviation for exponential is 1/lambda\n",
        "expected_mean_of_means = 1/lambda_exp\n",
        "expected_std_dev_of_means = (1/lambda_exp) / np.sqrt(sample_size)\n",
        "\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "p = (1 / (expected_std_dev_of_means * np.sqrt(2 * np.pi))) * np.exp(-((x - expected_mean_of_means) ** 2) / (2 * expected_std_dev_of_means ** 2))\n",
        "plt.plot(x, p, 'k', linewidth=2, label='Theoretical Normal Distribution')\n",
        "\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Density')\n",
        "plt.title(f'Distribution of Sample Means (CLT Demonstration) - Exponential Distribution\\nSample Size={sample_size}, Number of Samples={num_samples}')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wntu7ODMFcTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11 Simulate multiple samples from a normal distribution and verify the Central Limit Theorem\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Define the parameters for the normal distribution\n",
        "mu = 10  # Mean\n",
        "sigma = 2 # Standard deviation\n",
        "\n",
        "# Define the parameters for the simulation\n",
        "sample_size = 50 # Size of each sample\n",
        "num_samples = 1000 # Number of samples to draw\n",
        "\n",
        "# Simulate multiple samples from the normal distribution and calculate their means\n",
        "sample_means_normal = []\n",
        "for _ in range(num_samples):\n",
        "  normal_sample = np.random.normal(mu, sigma, sample_size)\n",
        "  sample_means_normal.append(np.mean(normal_sample))\n",
        "\n",
        "# Plot the histogram of the sample means\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(sample_means_normal, bins=50, density=True, color='teal', edgecolor='black')\n",
        "\n",
        "# Plot the theoretical normal distribution for the sample means based on CLT\n",
        "# The mean of the distribution of sample means is the population mean (mu)\n",
        "# The standard deviation of the distribution of sample means is the population standard deviation divided by the square root of the sample size (sigma / sqrt(sample_size))\n",
        "expected_mean_of_means_normal = mu\n",
        "expected_std_dev_of_means_normal = sigma / np.sqrt(sample_size)\n",
        "\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "p = (1 / (expected_std_dev_of_means_normal * np.sqrt(2 * np.pi))) * np.exp(-((x - expected_mean_of_means_normal) ** 2) / (2 * expected_std_dev_of_means_normal ** 2))\n",
        "plt.plot(x, p, 'k', linewidth=2, label='Theoretical Normal Distribution of Sample Means')\n",
        "\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Density')\n",
        "plt.title(f'Distribution of Sample Means (Normal Distribution Source)\\nSample Size={sample_size}, Number of Samples={num_samples}')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ajMATVScGFIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12 Write a Python function to calculate and plot the standard normal distribution (mean = 0, std = 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_standard_normal_distribution():\n",
        "  \"\"\"\n",
        "  Calculates and plots the standard normal distribution (mean = 0, std = 1).\n",
        "  \"\"\"\n",
        "  # Define the range of x values for the plot\n",
        "  x = np.linspace(-4, 4, 100) # From -4 to 4 standard deviations\n",
        "\n",
        "  # Calculate the probability density function (PDF) for the standard normal distribution\n",
        "  # Use scipy.stats.norm.pdf for the standard normal distribution (mean=0, std=1)\n",
        "  pdf_values = norm.pdf(x, loc=0, scale=1)\n",
        "\n",
        "  # Plot the standard normal distribution\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(x, pdf_values, label='Standard Normal Distribution (μ=0, σ=1)', color='blue')\n",
        "  plt.xlabel('Value')\n",
        "  plt.ylabel('Density')\n",
        "  plt.title('Standard Normal Distribution')\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Call the function to plot the standard normal distribution\n",
        "plot_standard_normal_distribution()"
      ],
      "metadata": {
        "id": "HOSlnmLtGNKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13 Generate random variables and calculate their corresponding probabilities using the binomial distribution\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import binom\n",
        "\n",
        "def calculate_binomial_probability(k, n, p):\n",
        "  \"\"\"\n",
        "  Calculates the probability of getting exactly k successes in n trials\n",
        "  with a success probability of p using the binomial distribution.\n",
        "\n",
        "  Args:\n",
        "    k: The number of successes.\n",
        "    n: The number of trials.\n",
        "    p: The probability of success in a single trial.\n",
        "\n",
        "  Returns:\n",
        "    The probability P(X=k).\n",
        "  \"\"\"\n",
        "  if not 0 <= p <= 1:\n",
        "    raise ValueError(\"Probability p must be between 0 and 1.\")\n",
        "  if not 0 <= k <= n:\n",
        "    raise ValueError(f\"Number of successes k must be between 0 and number of trials n ({n}).\")\n",
        "\n",
        "  return binom.pmf(k, n, p)\n",
        "\n",
        "# Example usage: Generate random variables (number of successes) and calculate probabilities\n",
        "\n",
        "# Define parameters for the binomial distribution\n",
        "n_trials = 20  # Number of trials\n",
        "p_success = 0.4 # Probability of success\n",
        "\n",
        "# Generate a few random variables (number of successes)\n",
        "num_random_vars = 5\n",
        "random_successes = np.random.binomial(n_trials, p_success, num_random_vars)\n",
        "\n",
        "print(f\"Generating {num_random_vars} random variables from Binomial(n={n_trials}, p={p_success}):\")\n",
        "for rv in random_successes:\n",
        "  probability = calculate_binomial_probability(rv, n_trials, p_success)\n",
        "  print(f\"Random variable: {rv}, Probability P(X={rv}): {probability:.4f}\")\n",
        "\n",
        "# You can also calculate probabilities for a range of possible outcomes\n",
        "possible_outcomes = np.arange(0, n_trials + 1)\n",
        "probabilities_for_outcomes = [calculate_binomial_probability(k, n_trials, p_success) for k in possible_outcomes]\n",
        "\n",
        "# Plot the probability mass function (PMF)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(possible_outcomes, probabilities_for_outcomes, color='teal')\n",
        "plt.xlabel('Number of Successes (k)')\n",
        "plt.ylabel('Probability P(X=k)')\n",
        "plt.title(f'Binomial Distribution PMF (n={n_trials}, p={p_success})')\n",
        "plt.xticks(possible_outcomes)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LgChWlTQHJMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14 Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal distribution\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def calculate_z_score(data_point, mean, std_dev):\n",
        "  \"\"\"\n",
        "  Calculates the Z-score for a given data point.\n",
        "\n",
        "  Args:\n",
        "    data_point: The value for which to calculate the Z-score.\n",
        "    mean: The mean of the dataset.\n",
        "    std_dev: The standard deviation of the dataset.\n",
        "\n",
        "  Returns:\n",
        "    The Z-score.\n",
        "  \"\"\"\n",
        "  if std_dev == 0:\n",
        "    return float('inf') if data_point > mean else float('-inf') if data_point < mean else 0\n",
        "  return (data_point - mean) / std_dev\n",
        "\n",
        "# Example usage:\n",
        "data = [65, 70, 75, 80, 85, 90, 95]\n",
        "data_point_to_check = 90\n",
        "\n",
        "# Calculate mean and standard deviation of the data\n",
        "mean_data = np.mean(data)\n",
        "std_dev_data = np.std(data)\n",
        "\n",
        "# Calculate the Z-score for the data point\n",
        "z_score = calculate_z_score(data_point_to_check, mean_data, std_dev_data)\n",
        "\n",
        "print(f\"Data point: {data_point_to_check}\")\n",
        "print(f\"Mean of data: {mean_data:.2f}\")\n",
        "print(f\"Standard deviation of data: {std_dev_data:.2f}\")\n",
        "print(f\"Z-score for {data_point_to_check}: {z_score:.2f}\")\n",
        "\n",
        "# Compare the Z-score to the standard normal distribution\n",
        "# We can find the probability of observing a Z-score this extreme or more extreme\n",
        "# using the cumulative distribution function (CDF) of the standard normal distribution.\n",
        "\n",
        "# Probability of observing a value less than or equal to the data point\n",
        "probability_less_than_or_equal = norm.cdf(z_score)\n",
        "print(f\"Probability of observing a value less than or equal to {data_point_to_check} (corresponding to Z-score {z_score:.2f}) in a standard normal distribution: {probability_less_than_or_equal:.4f}\")\n",
        "\n",
        "# Probability of observing a value greater than or equal to the data point\n",
        "probability_greater_than_or_equal = 1 - probability_less_than_or_equal\n",
        "print(f\"Probability of observing a value greater than or equal to {data_point_to_check} in a standard normal distribution: {probability_greater_than_or_equal:.4f}\")\n",
        "\n",
        "# Visualize the Z-score on the standard normal distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "x = np.linspace(-3, 3, 100)\n",
        "plt.plot(x, norm.pdf(x, 0, 1), label='Standard Normal Distribution (μ=0, σ=1)', color='blue')\n",
        "\n",
        "# Mark the calculated Z-score on the plot\n",
        "plt.axvline(z_score, color='red', linestyle='dashed', linewidth=2, label=f'Z-score = {z_score:.2f}')\n",
        "\n",
        "# Highlight the area corresponding to the probability\n",
        "# For example, highlight the area to the right of the Z-score (for probability_greater_than_or_equal)\n",
        "x_fill = np.linspace(z_score, 3, 100)\n",
        "plt.fill_between(x_fill, norm.pdf(x_fill, 0, 1), color='red', alpha=0.3, label=f'P(Z >= {z_score:.2f}) = {probability_greater_than_or_equal:.4f}')\n",
        "\n",
        "\n",
        "plt.xlabel('Z-score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Z-score Comparison to Standard Normal Distribution')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QVmUdBPrHWqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15 Implement hypothesis testing using Z-statistics for a sample dataset\n",
        "\n",
        "import numpy as np\n",
        "from statsmodels.stats.weightstats import ztest\n",
        "\n",
        "# Sample data (replace with your actual dataset)\n",
        "# Let's assume this data represents measurements from a sample.\n",
        "sample_data = np.array([52, 55, 58, 60, 63, 65, 67, 70, 72, 75])\n",
        "\n",
        "# Define the null hypothesis (H0): The population mean is equal to a specific value (e.g., 60)\n",
        "# Define the alternative hypothesis (Ha): The population mean is not equal to the specific value (two-tailed test)\n",
        "null_hypothesis_mean = 60\n",
        "\n",
        "# Perform the Z-test\n",
        "# The ztest function returns the Z-statistic and the p-value\n",
        "z_statistic, p_value = ztest(sample_data, value=null_hypothesis_mean)\n",
        "\n",
        "# Define the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"Sample Data: {sample_data}\")\n",
        "print(f\"Null Hypothesis (H0): Population Mean = {null_hypothesis_mean}\")\n",
        "print(f\"Z-statistic: {z_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Significance Level (alpha): {alpha}\")\n",
        "\n",
        "# Make a decision based on the p-value and significance level\n",
        "if p_value < alpha:\n",
        "  print(\"\\nDecision: Reject the null hypothesis.\")\n",
        "  print(f\"Conclusion: There is sufficient evidence to suggest that the population mean is significantly different from {null_hypothesis_mean} at the {alpha} significance level.\")\n",
        "else:\n",
        "  print(\"\\nDecision: Fail to reject the null hypothesis.\")\n",
        "  print(f\"Conclusion: There is not enough evidence to suggest that the population mean is significantly different from {null_hypothesis_mean} at the {alpha} significance level.\")\n",
        "\n",
        "# You can also perform one-tailed tests by specifying the 'alternative' parameter:\n",
        "# 'two-sided': alternative is mu != value (default)\n",
        "# 'larger': alternative is mu > value\n",
        "# 'smaller': alternative is mu < value\n",
        "\n",
        "# Example of a one-tailed test (alternative: population mean is greater than 60)\n",
        "z_statistic_larger, p_value_larger = ztest(sample_data, value=null_hypothesis_mean, alternative='larger')\n",
        "print(f\"\\nOne-tailed test (Ha: mu > {null_hypothesis_mean}):\")\n",
        "print(f\"Z-statistic: {z_statistic_larger:.4f}\")\n",
        "print(f\"P-value: {p_value_larger:.4f}\")\n",
        "\n",
        "if p_value_larger < alpha:\n",
        "  print(\"Decision: Reject the null hypothesis.\")\n",
        "  print(f\"Conclusion: There is sufficient evidence to suggest that the population mean is significantly greater than {null_hypothesis_mean}.\")\n",
        "else:\n",
        "  print(\"Decision: Fail to reject the null hypothesis.\")\n",
        "  print(f\"Conclusion: There is not enough evidence to suggest that the population mean is significantly greater than {null_hypothesis_mean}.\")"
      ],
      "metadata": {
        "id": "bvnb3BvMHvC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16 Create a confidence interval for a dataset using Python and interpret the result\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Assume 'sample_data' is the dataset you want to create a confidence interval for.\n",
        "# This data is already defined in the preceding code.\n",
        "\n",
        "# Define the confidence level\n",
        "confidence_level = 0.95\n",
        "alpha = 1 - confidence_level\n",
        "\n",
        "# Calculate the sample mean and sample standard deviation\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_std = np.std(sample_data, ddof=1) # Use ddof=1 for sample standard deviation (unbiased estimator)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "# Determine the appropriate distribution for the confidence interval\n",
        "# Since the sample size is small (< 30) and the population standard deviation is unknown,\n",
        "# we should use the t-distribution. If sample size was large (> 30) or population\n",
        "# standard deviation was known, we would use the normal (z) distribution.\n",
        "\n",
        "# Calculate the t-score (critical value) for the desired confidence level and degrees of freedom\n",
        "# Degrees of freedom for a one-sample t-interval is n - 1\n",
        "degrees_of_freedom = sample_size - 1\n",
        "t_score = stats.t.ppf(1 - alpha/2, degrees_of_freedom) # For a two-tailed interval\n",
        "\n",
        "# Calculate the standard error of the mean (SEM)\n",
        "standard_error = sample_std / np.sqrt(sample_size)\n",
        "\n",
        "# Calculate the margin of error\n",
        "margin_of_error = t_score * standard_error\n",
        "\n",
        "# Calculate the confidence interval\n",
        "confidence_interval_lower = sample_mean - margin_of_error\n",
        "confidence_interval_upper = sample_mean + margin_of_error\n",
        "\n",
        "print(f\"Dataset: {sample_data}\")\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Sample Standard Deviation: {sample_std:.2f}\")\n",
        "print(f\"Sample Size: {sample_size}\")\n",
        "print(f\"Confidence Level: {confidence_level}\")\n",
        "print(f\"Degrees of Freedom: {degrees_of_freedom}\")\n",
        "print(f\"T-score (critical value): {t_score:.4f}\")\n",
        "print(f\"Standard Error of the Mean (SEM): {standard_error:.4f}\")\n",
        "print(f\"Margin of Error: {margin_of_error:.4f}\")\n",
        "print(f\"\\n{confidence_level*100:.0f}% Confidence Interval: ({confidence_interval_lower:.4f}, {confidence_interval_upper:.4f})\")\n",
        "\n",
        "# Interpretation of the result\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"We are {confidence_level*100:.0f}% confident that the true population mean lies within the interval [{confidence_interval_lower:.4f}, {confidence_interval_upper:.4f}].\")\n",
        "print(\"This means that if we were to take many random samples from the same population and construct a confidence interval for each sample,\")\n",
        "print(f\"approximately {confidence_level*100:.0f}% of these intervals would contain the true population mean.\")\n",
        "print(\"It does NOT mean that there is a 95% probability that the true population mean falls within this specific interval.\")"
      ],
      "metadata": {
        "id": "i3uCMBiZH777"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17 Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Generate data from a normal distribution\n",
        "mu = 50  # Mean of the normal distribution\n",
        "sigma = 10 # Standard deviation of the normal distribution\n",
        "sample_size = 100  # Number of data points\n",
        "\n",
        "normal_data = np.random.normal(mu, sigma, sample_size)\n",
        "\n",
        "# Calculate the confidence interval for the mean\n",
        "confidence_level = 0.95\n",
        "alpha = 1 - confidence_level\n",
        "\n",
        "# Calculate sample statistics\n",
        "sample_mean = np.mean(normal_data)\n",
        "sample_std = np.std(normal_data, ddof=1) # Use ddof=1 for sample standard deviation (unbiased estimator)\n",
        "n = len(normal_data)\n",
        "\n",
        "# Determine the appropriate distribution for the confidence interval\n",
        "# Since we generated the data, we know the population standard deviation (sigma).\n",
        "# However, in a real scenario, you'd likely use the sample standard deviation (sample_std)\n",
        "# and the t-distribution unless the sample size is very large.\n",
        "# For demonstration with known population standard deviation, we can use the Z-distribution.\n",
        "# If we were to rely solely on the sample, we'd use the t-distribution as shown in the previous cell.\n",
        "\n",
        "# Using Z-distribution (assuming population sigma is known or sample size is large)\n",
        "# Find the critical Z-value\n",
        "z_critical = norm.ppf(1 - alpha/2) # For a two-tailed interval\n",
        "\n",
        "# Calculate the standard error of the mean (SEM)\n",
        "# If using population standard deviation: sem = sigma / np.sqrt(n)\n",
        "# If using sample standard deviation (more common in practice): sem = sample_std / np.sqrt(n)\n",
        "standard_error = sample_std / np.sqrt(n) # Using sample standard deviation\n",
        "\n",
        "# Calculate the margin of error\n",
        "margin_of_error = z_critical * standard_error\n",
        "\n",
        "# Calculate the confidence interval\n",
        "confidence_interval_lower = sample_mean - margin_of_error\n",
        "confidence_interval_upper = sample_mean + margin_of_error\n",
        "\n",
        "print(f\"Generated Data from Normal Distribution (μ={mu}, σ={sigma}): First 10 values: {normal_data[:10]}...\")\n",
        "print(f\"Sample Mean: {sample_mean:.4f}\")\n",
        "print(f\"Sample Standard Deviation: {sample_std:.4f}\")\n",
        "print(f\"Sample Size: {n}\")\n",
        "print(f\"Confidence Level: {confidence_level}\")\n",
        "print(f\"Z-score (critical value): {z_critical:.4f}\")\n",
        "print(f\"Standard Error of the Mean (SEM): {standard_error:.4f}\")\n",
        "print(f\"Margin of Error: {margin_of_error:.4f}\")\n",
        "print(f\"\\n{confidence_level*100:.0f}% Confidence Interval for the Mean: ({confidence_interval_lower:.4f}, {confidence_interval_upper:.4f})\")\n",
        "\n",
        "# Interpretation of the result\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"Based on our sample of {n} data points, we are {confidence_level*100:.0f}% confident that the true mean of the population from which this data was drawn\")\n",
        "print(f\"lies within the range [{confidence_interval_lower:.4f}, {confidence_interval_upper:.4f}].\")\n",
        "print(f\"Since we generated the data from a normal distribution with a true mean (μ) of {mu},\")\n",
        "print(f\"we can check if the true mean falls within our calculated confidence interval.\")\n",
        "print(f\"Is the true mean ({mu}) within the interval [{confidence_interval_lower:.4f}, {confidence_interval_upper:.4f}]? {confidence_interval_lower <= mu <= confidence_interval_upper}\")\n",
        "print(\"In general, if we were to repeat this process of taking samples and calculating confidence intervals many times,\")\n",
        "print(f\"approximately {confidence_level*100:.0f}% of those intervals would contain the true population mean.\")\n",
        "\n",
        "# Optional: Visualize the data and the confidence interval on a histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(normal_data, bins=30, density=True, alpha=0.6, color='skyblue', label='Data Histogram')\n",
        "\n",
        "# Plot the theoretical normal distribution from which data was generated\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "p = norm.pdf(x, mu, sigma)\n",
        "plt.plot(x, p, 'k', linewidth=2, label=f'True Normal PDF (μ={mu}, σ={sigma})')\n",
        "\n",
        "# Mark the sample mean\n",
        "plt.axvline(sample_mean, color='red', linestyle='dashed', linewidth=2, label=f'Sample Mean: {sample_mean:.2f}')\n",
        "\n",
        "# Mark the confidence interval\n",
        "plt.axvline(confidence_interval_lower, color='green', linestyle='dotted', linewidth=2, label=f'{confidence_level*100:.0f}% CI')\n",
        "plt.axvline(confidence_interval_upper, color='green', linestyle='dotted', linewidth=2)\n",
        "plt.fill_betweenx([0, plt.ylim()[1]], confidence_interval_lower, confidence_interval_upper, color='green', alpha=0.1)\n",
        "\n",
        "\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Generated Normal Data and Confidence Interval for the Mean')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "16LxV8c7INur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18 Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plot_normal_distribution_pdf(mean, std_dev):\n",
        "  \"\"\"\n",
        "  Calculates and plots the probability density function (PDF)\n",
        "  of a normal distribution.\n",
        "\n",
        "  Args:\n",
        "    mean: The mean (μ) of the normal distribution.\n",
        "    std_dev: The standard deviation (σ) of the normal distribution.\n",
        "  \"\"\"\n",
        "  # Define the range of x values for the plot\n",
        "  # It's common to plot a few standard deviations around the mean\n",
        "  x = np.linspace(mean - 4*std_dev, mean + 4*std_dev, 100)\n",
        "\n",
        "  # Calculate the probability density function (PDF) for the normal distribution\n",
        "  # Using the formula: PDF(x) = (1 / (σ * sqrt(2*π))) * exp(-((x - μ)^2) / (2 * σ^2))\n",
        "  # Or using scipy.stats.norm.pdf\n",
        "  pdf_values = norm.pdf(x, loc=mean, scale=std_dev)\n",
        "\n",
        "  # Plot the PDF\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(x, pdf_values, label=f'Normal Distribution (μ={mean}, σ={std_dev})', color='blue')\n",
        "  plt.xlabel('Value')\n",
        "  plt.ylabel('Density')\n",
        "  plt.title('Probability Density Function of a Normal Distribution')\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# Plot a normal distribution with mean 0 and standard deviation 1 (standard normal distribution)\n",
        "plot_normal_distribution_pdf(0, 1)\n",
        "\n",
        "# Plot a normal distribution with mean 10 and standard deviation 2\n",
        "plot_normal_distribution_pdf(10, 2)"
      ],
      "metadata": {
        "id": "hEtIhTLxIZq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19 Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import poisson\n",
        "\n",
        "# Define the average rate (lambda)\n",
        "lambda_val = 3  # Example average rate of events\n",
        "\n",
        "# Define the range of possible outcomes for the CDF\n",
        "# The CDF is typically calculated for integer values k\n",
        "# We can go up to a certain number of events where the probability becomes very low\n",
        "max_k = int(poisson.ppf(0.999, lambda_val)) # Find k value up to which CDF is 0.999\n",
        "possible_k_values = np.arange(0, max_k + 1)\n",
        "\n",
        "# Calculate the cumulative distribution function (CDF) for each possible k\n",
        "# The CDF at k is the probability that the number of events is less than or equal to k, P(X <= k)\n",
        "cdf_values = poisson.cdf(possible_k_values, lambda_val)\n",
        "\n",
        "print(f\"Calculating CDF for Poisson Distribution with λ={lambda_val}:\")\n",
        "for k, cdf in zip(possible_k_values, cdf_values):\n",
        "  print(f\"CDF at k={k} (P(X <= {k})): {cdf:.4f}\")\n",
        "\n",
        "# Plot the CDF\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.step(possible_k_values, cdf_values, where='post', color='darkorange', label=f'Poisson CDF (λ={lambda_val})')\n",
        "plt.xlabel('Number of Events (k)')\n",
        "plt.ylabel('Cumulative Probability P(X <= k)')\n",
        "plt.title(f'Cumulative Distribution Function of a Poisson Distribution (λ={lambda_val})')\n",
        "plt.xticks(possible_k_values)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Interpretation of the CDF\n",
        "print(\"\\nInterpretation of the Poisson CDF:\")\n",
        "print(\"The CDF at a specific value 'k' represents the probability of observing 'k' or fewer events in a fixed interval or space,\")\n",
        "print(f\"given that the average rate of events is {lambda_val}.\")\n",
        "print(f\"For example, the CDF at k={max_k // 2} is {poisson.cdf(max_k // 2, lambda_val):.4f}. This means there is a {poisson.cdf(max_k // 2, lambda_val)*100:.2f}% chance of observing {max_k // 2} or fewer events.\")\n",
        "print(\"As 'k' increases, the CDF value approaches 1, indicating that it becomes almost certain to observe a number of events less than or equal to a large value 'k'.\")"
      ],
      "metadata": {
        "id": "u1EwoLcQIl3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20 Simulate a random variable using a continuous uniform distribution and calculate its expected value\n",
        "\n",
        "import numpy as np\n",
        "# Simulate a random variable from a continuous uniform distribution\n",
        "# Define the parameters of the continuous uniform distribution\n",
        "low_val = 5  # Lower bound\n",
        "high_val = 15 # Upper bound\n",
        "\n",
        "# Generate one random variable from the continuous uniform distribution\n",
        "random_variable_uniform = np.random.uniform(low_val, high_val)\n",
        "\n",
        "print(f\"Simulated random variable from Continuous Uniform distribution [{low_val}, {high_val}]: {random_variable_uniform:.4f}\")\n",
        "\n",
        "# Calculate the expected value of the continuous uniform distribution\n",
        "# The expected value (mean) of a continuous uniform distribution U(a, b) is (a + b) / 2\n",
        "expected_value_uniform = (low_val + high_val) / 2\n",
        "\n",
        "print(f\"Calculated Expected Value of Continuous Uniform distribution [{low_val}, {high_val}]: {expected_value_uniform:.4f}\")\n",
        "\n",
        "# You can also verify this by taking the mean of many samples (demonstrated in a previous cell)\n",
        "# mean of uniform_samples generated in cell 7 should be close to the expected value\n",
        "# print(f\"Mean of 1000 uniform samples: {np.mean(uniform_samples):.4f}\")"
      ],
      "metadata": {
        "id": "L72pB9_-Iw6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21  Write a Python program to compare the standard deviations of two datasets and visualize the difference\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def compare_std_devs(data1, data2):\n",
        "  \"\"\"\n",
        "    Compares the standard deviations of two datasets and visualizes the difference.\n",
        "\n",
        "    Args:\n",
        "      data1: The first dataset (list or NumPy array).\n",
        "      data2: The second dataset (list or NumPy array).\n",
        "    \"\"\"\n",
        "  std_dev1 = np.std(data1)\n",
        "  std_dev2 = np.std(data2)\n",
        "\n",
        "  print(f\"Standard Deviation of Dataset 1: {std_dev1:.4f}\")\n",
        "  print(f\"Standard Deviation of Dataset 2: {std_dev2:.4f}\")\n",
        "\n",
        "  # Visualize the difference\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  std_devs = [std_dev1, std_dev2]\n",
        "  labels = ['Dataset 1', 'Dataset 2']\n",
        "  colors = ['blue', 'orange']\n",
        "\n",
        "  plt.bar(labels, std_devs, color=colors)\n",
        "  plt.ylabel('Standard Deviation')\n",
        "  plt.title('Comparison of Standard Deviations')\n",
        "  plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "  plt.show()\n",
        "\n",
        "  # Optional: Visualize the distributions themselves to see the spread\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.hist(data1, bins=30, density=True, alpha=0.6, color='blue', label='Dataset 1')\n",
        "  plt.hist(data2, bins=30, density=True, alpha=0.6, color='orange', label='Dataset 2')\n",
        "  plt.xlabel('Value')\n",
        "  plt.ylabel('Density')\n",
        "  plt.title('Distribution of Datasets')\n",
        "  plt.legend()\n",
        "  plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Example Usage:\n",
        "# Create two example datasets with different standard deviations\n",
        "dataset1 = np.random.normal(loc=10, scale=2, size=100) # Mean 10, Std Dev 2\n",
        "dataset2 = np.random.normal(loc=10, scale=5, size=100) # Mean 10, Std Dev 5\n",
        "\n",
        "compare_std_devs(dataset1, dataset2)\n",
        "\n",
        "# Example with the sample_data from previous cells and another generated dataset\n",
        "dataset3 = np.random.normal(loc=70, scale=8, size=len(sample_data))\n",
        "\n",
        "compare_std_devs(sample_data, dataset3)"
      ],
      "metadata": {
        "id": "STng5KCLI5bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22 Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Assuming 'normal_samples' was generated in cell 8\n",
        "# Define the dataset from the normal distribution simulation in cell 8\n",
        "dataset_for_range = normal_samples\n",
        "\n",
        "# Calculate the range\n",
        "data_range = np.max(dataset_for_range) - np.min(dataset_for_range)\n",
        "\n",
        "# Calculate the Interquartile Range (IQR)\n",
        "# IQR = Q3 - Q1\n",
        "Q1 = np.percentile(dataset_for_range, 25)\n",
        "Q3 = np.percentile(dataset_for_range, 75)\n",
        "iqr = Q3 - Q1\n",
        "\n",
        "print(f\"Dataset from Normal Distribution (first 10 values): {dataset_for_range[:10]}...\")\n",
        "print(f\"Number of data points: {len(dataset_for_range)}\")\n",
        "print(f\"Range: {data_range:.4f}\")\n",
        "print(f\"First Quartile (Q1): {Q1:.4f}\")\n",
        "print(f\"Third Quartile (Q3): {Q3:.4f}\")\n",
        "print(f\"Interquartile Range (IQR): {iqr:.4f}\")\n",
        "\n",
        "# Optional: Visualize the quartiles and IQR on a box plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot(dataset_for_range, vert=False, patch_artist=True,\n",
        "            boxprops=dict(facecolor='lightblue'),\n",
        "            medianprops=dict(color='red', linewidth=2))\n",
        "plt.title('Box Plot of the Normal Distribution Dataset')\n",
        "plt.xlabel('Value')\n",
        "plt.yticks([]) # Hide y-axis ticks for a single box plot\n",
        "plt.text(Q1, 1.05, f'Q1\\n{Q1:.2f}', ha='center', color='blue')\n",
        "plt.text(Q3, 1.05, f'Q3\\n{Q3:.2f}', ha='center', color='blue')\n",
        "plt.text(np.median(dataset_for_range), 1.05, f'Median\\n{np.median(dataset_for_range):.2f}', ha='center', color='red')\n",
        "plt.text(Q1 + iqr/2, 0.8, f'IQR = {iqr:.2f}', ha='center', color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "91lXNME3JC37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23 Implement Z-score normalization on a dataset and visualize its transformation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Implement Z-score normalization on a dataset and visualize its transformation\n",
        "\n",
        "def z_score_normalize(data):\n",
        "  \"\"\"\n",
        "  Applies Z-score normalization to a dataset.\n",
        "\n",
        "  Args:\n",
        "    data: A list or NumPy array of numerical data.\n",
        "\n",
        "  Returns:\n",
        "    A NumPy array of the Z-score normalized data.\n",
        "  \"\"\"\n",
        "  mean = np.mean(data)\n",
        "  std_dev = np.std(data)\n",
        "\n",
        "  if std_dev == 0:\n",
        "    # Handle case where standard deviation is zero (all data points are the same)\n",
        "    return np.zeros_like(data)\n",
        "  else:\n",
        "    return (data - mean) / std_dev\n",
        "\n",
        "# Example usage:\n",
        "# Create a sample dataset that is not normalized\n",
        "unnormalized_data = np.array([10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
        "\n",
        "# Apply Z-score normalization\n",
        "normalized_data = z_score_normalize(unnormalized_data)\n",
        "\n",
        "print(f\"Original Data: {unnormalized_data}\")\n",
        "print(f\"Z-score Normalized Data: {normalized_data}\")\n",
        "\n",
        "# Verify the mean and standard deviation of the normalized data\n",
        "mean_normalized = np.mean(normalized_data)\n",
        "std_dev_normalized = np.std(normalized_data)\n",
        "print(f\"Mean of Normalized Data: {mean_normalized:.4f}\")\n",
        "print(f\"Standard Deviation of Normalized Data: {std_dev_normalized:.4f}\")\n",
        "# The mean should be very close to 0 and standard deviation very close to 1.\n",
        "\n",
        "# Visualize the transformation\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot original data histogram\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(unnormalized_data, bins=5, density=True, color='skyblue', edgecolor='black')\n",
        "plt.xlabel('Original Value')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Original Data')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Plot normalized data histogram\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(normalized_data, bins=5, density=True, color='lightgreen', edgecolor='black')\n",
        "\n",
        "# Overlay the standard normal distribution PDF for comparison\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "p = norm.pdf(x, 0, 1) # Standard normal distribution PDF\n",
        "plt.plot(x, p, 'k', linewidth=2, label='Standard Normal PDF')\n",
        "\n",
        "plt.xlabel('Normalized Value (Z-score)')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Z-score Normalized Data')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4sEXPHT0JMf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24 Write a Python function to calculate the skewness and kurtosis of a dataset generated from a normal distribution.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def calculate_skewness_kurtosis(data):\n",
        "  \"\"\"\n",
        "  Calculates the skewness and kurtosis of a dataset.\n",
        "\n",
        "  Args:\n",
        "    data: A list or NumPy array of numerical data.\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing the skewness and kurtosis of the dataset.\n",
        "  \"\"\"\n",
        "  skewness = stats.skew(data)\n",
        "  kurtosis = stats.kurtosis(data) # By default, returns excess kurtosis (kurtosis - 3)\n",
        "  return skewness, kurtosis\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'normal_samples' was generated in cell 8\n",
        "# This data is generated from a normal distribution.\n",
        "dataset = normal_samples\n",
        "\n",
        "skewness, kurtosis = calculate_skewness_kurtosis(dataset)\n",
        "\n",
        "print(f\"Dataset from Normal Distribution (first 10 values): {dataset[:10]}...\")\n",
        "print(f\"Number of data points: {len(dataset)}\")\n",
        "print(f\"Skewness: {skewness:.4f}\")\n",
        "print(f\"Kurtosis (Excess): {kurtosis:.4f}\")\n",
        "\n",
        "# Interpretation for a normal distribution:\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"For a perfectly normal distribution:\")\n",
        "print(\"- Skewness should be close to 0 (indicating symmetry).\")\n",
        "print(\"- Kurtosis (Excess) should be close to 0 (indicating mesokurtic distribution).\")\n",
        "print(\"\\nOur calculated values for the sample from a normal distribution:\")\n",
        "print(f\"- Skewness ({skewness:.4f}) is close to 0, as expected for a normal distribution.\")\n",
        "print(f\"- Kurtosis ({kurtosis:.4f}) is close to 0, as expected for a normal distribution.\")\n",
        "print(\"Small deviations from 0 are expected due to sampling variability.\")\n",
        "\n",
        "# You can also visualize the distribution to intuitively see the skewness and kurtosis\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(dataset, bins=50, density=True, color='lightblue', edgecolor='black', alpha=0.7, label='Sample Histogram')\n",
        "\n",
        "# Plot the theoretical normal distribution PDF for comparison\n",
        "xmin, xmax = plt.xlim()\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "mean_data = np.mean(dataset)\n",
        "std_dev_data = np.std(dataset)\n",
        "p = norm.pdf(x, mean_data, std_dev_data)\n",
        "plt.plot(x, p, 'k', linewidth=2, label='Fitted Normal Distribution PDF')\n",
        "\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Histogram of Sample and Fitted Normal Distribution')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gB5EbUDyJcBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Part - 2"
      ],
      "metadata": {
        "id": "TwhQWE4HKL6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Task: Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results.\n",
        "# This task is a repetition of a previous task, but we will provide a slightly more structured example.\n",
        "\n",
        "# Define the known population parameters\n",
        "population_mean = 70      # μ₀ (Hypothesized population mean under the null hypothesis)\n",
        "population_std_dev = 10   # σ (Known population standard deviation) - This is crucial for a Z-test\n",
        "\n",
        "# Define the sample data\n",
        "sample_data = np.array([68, 72, 75, 65, 71, 73, 69, 70, 74, 67, 76, 66, 70, 72, 71]) # Example sample data\n",
        "\n",
        "# Calculate sample statistics\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "print(f\"Population Mean (H0): {population_mean}\")\n",
        "print(f\"Population Standard Deviation: {population_std_dev}\")\n",
        "print(f\"Sample Data: {sample_data}\")\n",
        "print(f\"Sample Mean: {sample_mean:.4f}\")\n",
        "print(f\"Sample Size: {sample_size}\")\n",
        "\n",
        "# Formulate the hypotheses\n",
        "# H₀: The sample mean is equal to the population mean (μ = μ₀)\n",
        "# Hₐ: The sample mean is not equal to the population mean (μ ≠ μ₀) (Two-tailed test)\n",
        "\n",
        "# Calculate the Z-statistic manually\n",
        "# Z = (sample_mean - population_mean) / (population_std_dev / sqrt(sample_size))\n",
        "standard_error = population_std_dev / np.sqrt(sample_size)\n",
        "z_statistic_manual = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "print(f\"\\nCalculated Z-statistic (Manual): {z_statistic_manual:.4f}\")\n",
        "\n",
        "# Alternatively, use the statsmodels ztest function (requires sample data, not just stats)\n",
        "# Note: The `ztest` function in `statsmodels.stats.weightstats` is primarily designed\n",
        "# for comparing sample mean to a value when population standard deviation is UNKNOWN\n",
        "# and sample size is large (it uses the sample standard deviation).\n",
        "# However, for direct comparison to a known population mean with known population std dev,\n",
        "# the manual calculation is more direct based on the Z-test definition.\n",
        "# If you use `ztest` with a known population std dev, you'd typically provide that.\n",
        "# Let's use the manual calculation for clarity matching the Z-test definition\n",
        "# using the known population std dev.\n",
        "\n",
        "# Find the p-value for the Z-statistic\n",
        "# For a two-tailed test, the p-value is 2 * P(Z > |z_statistic|)\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_statistic_manual)))\n",
        "\n",
        "print(f\"P-value (from Z-statistic): {p_value:.4f}\")\n",
        "\n",
        "# Define the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"Significance Level (alpha): {alpha}\")\n",
        "\n",
        "# Make a decision based on the p-value\n",
        "if p_value < alpha:\n",
        "  print(\"\\nDecision: Reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is sufficient statistical evidence at the {alpha} significance level to conclude that the true population mean is significantly different from the hypothesized mean ({population_mean}).\")\n",
        "else:\n",
        "  print(\"\\nDecision: Fail to reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is not enough statistical evidence at the {alpha} significance level to conclude that the true population mean is significantly different from the hypothesized mean ({population_mean}).\")\n",
        "\n",
        "# Interpretation in context\n",
        "print(\"\\nInterpretation:\")\n",
        "if p_value < alpha:\n",
        "  print(f\"Our observed sample mean ({sample_mean:.4f}) is statistically different from the hypothesized population mean of {population_mean}.\")\n",
        "  print(f\"The probability of observing a sample mean as extreme as or more extreme than {sample_mean:.4f}, assuming the true population mean is {population_mean}, is very small ({p_value:.4f}).\")\n",
        "else:\n",
        "  print(f\"Our observed sample mean ({sample_mean:.4f}) is not statistically different from the hypothesized population mean of {population_mean}.\")\n",
        "  print(f\"The probability of observing a sample mean as extreme as or more extreme than {sample_mean:.4f}, assuming the true population mean is {population_mean}, is {p_value:.4f}.\")\n",
        "  print(\"This value is greater than our significance level, so we do not have enough evidence to reject the initial assumption.\")\n",
        "\n",
        "# Optional: Visualize the Z-test\n",
        "# Plot the standard normal distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "x = np.linspace(-4, 4, 100)\n",
        "plt.plot(x, norm.pdf(x, 0, 1), label='Standard Normal Distribution (μ=0, σ=1)', color='blue')\n",
        "\n",
        "# Mark the calculated Z-statistic\n",
        "plt.axvline(z_statistic_manual, color='red', linestyle='dashed', linewidth=2, label=f'Z-statistic = {z_statistic_manual:.4f}')\n",
        "\n",
        "# Mark the critical Z-values for a two-tailed test at alpha\n",
        "z_critical_lower = norm.ppf(alpha/2)\n",
        "z_critical_upper = norm.ppf(1 - alpha/2)\n",
        "plt.axvline(z_critical_lower, color='green', linestyle='dotted', linewidth=2, label=f'Critical Z-values (α={alpha})')\n",
        "plt.axvline(z_critical_upper, color='green', linestyle='dotted', linewidth=2)\n",
        "\n",
        "# Shade the rejection regions\n",
        "x_reject_lower = np.linspace(-4, z_critical_lower, 50)\n",
        "plt.fill_between(x_reject_lower, norm.pdf(x_reject_lower, 0, 1), color='green', alpha=0.2, label='Rejection Region')\n",
        "x_reject_upper = np.linspace(z_critical_upper, 4, 50)\n",
        "plt.fill_between(x_reject_upper, norm.pdf(x_reject_upper, 0, 1), color='green', alpha=0.2)\n",
        "\n",
        "plt.xlabel('Z-score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Z-Test for One Sample Mean')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "IiNJZsNcKiKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Task: Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python\n",
        "\n",
        "# This task has been addressed within the provided code snippet.\n",
        "# Specifically, task #15 demonstrates hypothesis testing using Z-statistics for a sample dataset\n",
        "# and calculates the corresponding P-value.\n",
        "\n",
        "# Re-executing task #15 for clarity:\n",
        "\n",
        "# Implement hypothesis testing using Z-statistics for a sample dataset\n",
        "\n",
        "# Sample data (replace with your actual dataset)\n",
        "# Let's assume this data represents measurements from a sample.\n",
        "sample_data = np.array([52, 55, 58, 60, 63, 65, 67, 70, 72, 75])\n",
        "\n",
        "# Define the null hypothesis (H0): The population mean is equal to a specific value (e.g., 60)\n",
        "# Define the alternative hypothesis (Ha): The population mean is not equal to the specific value (two-tailed test)\n",
        "null_hypothesis_mean = 60\n",
        "\n",
        "# Perform the Z-test\n",
        "# The ztest function returns the Z-statistic and the p-value\n",
        "# Note: As mentioned previously, ztest from statsmodels uses the sample std dev by default.\n",
        "# If the population std dev is known, a manual calculation or a different function might be preferred\n",
        "# if the sample size is small. However, for demonstration and common usage with larger samples,\n",
        "# ztest is a convenient option. Let's use it as in the original example.\n",
        "z_statistic, p_value = ztest(sample_data, value=null_hypothesis_mean)\n",
        "\n",
        "# Define the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"Sample Data: {sample_data}\")\n",
        "print(f\"Null Hypothesis (H0): Population Mean = {null_hypothesis_mean}\")\n",
        "print(f\"Z-statistic: {z_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Significance Level (alpha): {alpha}\")\n",
        "\n",
        "# Make a decision based on the p-value and significance level\n",
        "if p_value < alpha:\n",
        "  print(\"\\nDecision: Reject the null hypothesis.\")\n",
        "  print(f\"Conclusion: There is sufficient evidence to suggest that the population mean is significantly different from {null_hypothesis_mean} at the {alpha} significance level.\")\n",
        "else:\n",
        "  print(\"\\nDecision: Fail to reject the null hypothesis.\")\n",
        "  print(f\"Conclusion: There is not enough evidence to suggest that the population mean is significantly different from {null_hypothesis_mean} at the {alpha} significance level.\")\n",
        "\n",
        "# The P-value ({p_value:.4f}) is the key result showing the strength of evidence against the null hypothesis.\n",
        "# A smaller P-value means stronger evidence against H0.\n",
        "\n",
        "# Optional: Visualize the Z-test (reusing the code from task #25, but adapted to the ztest output)\n",
        "# Note: The `ztest` function uses the sample standard deviation, so the resulting Z-statistic\n",
        "# might be slightly different from a Z-test where the population standard deviation is truly known.\n",
        "# However, the interpretation relative to the standard normal distribution remains the same.\n",
        "\n",
        "# Plot the standard normal distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "x = np.linspace(-4, 4, 100)\n",
        "plt.plot(x, norm.pdf(x, 0, 1), label='Standard Normal Distribution (μ=0, σ=1)', color='blue')\n",
        "\n",
        "# Mark the calculated Z-statistic from ztest\n",
        "plt.axvline(z_statistic, color='red', linestyle='dashed', linewidth=2, label=f'Z-statistic = {z_statistic:.4f}')\n",
        "\n",
        "# Mark the critical Z-values for a two-tailed test at alpha\n",
        "z_critical_lower = norm.ppf(alpha/2)\n",
        "z_critical_upper = norm.ppf(1 - alpha/2)\n",
        "plt.axvline(z_critical_lower, color='green', linestyle='dotted', linewidth=2, label=f'Critical Z-values (α={alpha})')\n",
        "plt.axvline(z_critical_upper, color='green', linestyle='dotted', linewidth=2)\n",
        "\n",
        "# Shade the rejection regions\n",
        "x_reject_lower = np.linspace(-4, z_critical_lower, 50)\n",
        "plt.fill_between(x_reject_lower, norm.pdf(x_reject_lower, 0, 1), color='green', alpha=0.2, label='Rejection Region')\n",
        "x_reject_upper = np.linspace(z_critical_upper, 4, 50)\n",
        "plt.fill_between(x_reject_upper, norm.pdf(x_reject_upper, 0, 1), color='green', alpha=0.2)\n",
        "\n",
        "plt.xlabel('Z-score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Z-Test for One Sample Mean')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IAaz-r0mKt8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Implement a one-sample Z-test using Python to compare the sample mean with the population mean\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Define the sample data (replace with your actual sample data)\n",
        "# Example: A sample of 10 observations\n",
        "sample_data = np.array([62, 65, 68, 70, 73, 75, 78, 80, 83, 85])\n",
        "\n",
        "# Define the known or hypothesized population mean under the null hypothesis\n",
        "population_mean_h0 = 70      # μ₀\n",
        "\n",
        "# Define the known population standard deviation\n",
        "# This is required for a Z-test. If unknown and sample size is small, use a T-test.\n",
        "population_std_dev = 8      # σ\n",
        "\n",
        "# Calculate sample statistics\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_size = len(sample_data)\n",
        "\n",
        "print(f\"Sample Data: {sample_data}\")\n",
        "print(f\"Hypothesized Population Mean (H0): {population_mean_h0}\")\n",
        "print(f\"Known Population Standard Deviation: {population_std_dev}\")\n",
        "print(f\"Sample Mean: {sample_mean:.4f}\")\n",
        "print(f\"Sample Size: {sample_size}\")\n",
        "\n",
        "# Calculate the Z-statistic\n",
        "# Z = (sample_mean - population_mean_h0) / (population_std_dev / sqrt(sample_size))\n",
        "standard_error = population_std_dev / np.sqrt(sample_size)\n",
        "z_statistic = (sample_mean - population_mean_h0) / standard_error\n",
        "\n",
        "print(f\"\\nCalculated Z-statistic: {z_statistic:.4f}\")\n",
        "\n",
        "# Calculate the P-value\n",
        "# For a two-tailed test (Ha: μ ≠ μ₀), the p-value is the probability of observing a Z-statistic\n",
        "# as extreme as or more extreme than the calculated Z-statistic in either tail of the standard normal distribution.\n",
        "# p-value = 2 * P(Z > |z_statistic|)\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_statistic)))\n",
        "\n",
        "print(f\"P-value (two-tailed): {p_value:.4f}\")\n",
        "\n",
        "# Define the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"Significance Level (alpha): {alpha}\")\n",
        "\n",
        "# Make a decision based on the P-value\n",
        "if p_value < alpha:\n",
        "  print(\"\\nDecision: Reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is sufficient statistical evidence at the {alpha} significance level to conclude that the true population mean is significantly different from the hypothesized mean ({population_mean_h0}).\")\n",
        "else:\n",
        "  print(\"\\nDecision: Fail to reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is not enough statistical evidence at the {alpha} significance level to conclude that the true population mean is significantly different from the hypothesized mean ({population_mean_h0}).\")\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\nInterpretation:\")\n",
        "print(f\"The Z-statistic of {z_statistic:.4f} indicates that our sample mean of {sample_mean:.4f} is {abs(z_statistic):.2f} standard errors away from the hypothesized population mean of {population_mean_h0}.\")\n",
        "if p_value < alpha:\n",
        "  print(f\"The P-value of {p_value:.4f} is less than the significance level ({alpha}). This means there is a low probability ({p_value*100:.2f}%) of observing a sample mean as extreme as {sample_mean:.4f} if the true population mean were actually {population_mean_h0}.\")\n",
        "  print(\"Therefore, we reject the null hypothesis and conclude there is a significant difference.\")\n",
        "else:\n",
        "  print(f\"The P-value of {p_value:.4f} is greater than the significance level ({alpha}). This means there is a high probability ({p_value*100:.2f}%) of observing a sample mean as extreme as {sample_mean:.4f} if the true population mean were actually {population_mean_h0}.\")\n",
        "  print(\"Therefore, we fail to reject the null hypothesis. We do not have enough evidence to claim a significant difference.\")\n",
        "\n",
        "# Optional: Visualize the Z-test\n",
        "# Plot the standard normal distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "x = np.linspace(-4, 4, 100)\n",
        "plt.plot(x, norm.pdf(x, 0, 1), label='Standard Normal Distribution (μ=0, σ=1)', color='blue')\n",
        "\n",
        "# Mark the calculated Z-statistic\n",
        "plt.axvline(z_statistic, color='red', linestyle='dashed', linewidth=2, label=f'Z-statistic = {z_statistic:.4f}')\n",
        "\n",
        "# Mark the critical Z-values for a two-tailed test at alpha\n",
        "z_critical_lower = norm.ppf(alpha/2)\n",
        "z_critical_upper = norm.ppf(1 - alpha/2)\n",
        "plt.axvline(z_critical_lower, color='green', linestyle='dotted', linewidth=2, label=f'Critical Z-values (α={alpha})')\n",
        "plt.axvline(z_critical_upper, color='green', linestyle='dotted', linewidth=2)\n",
        "\n",
        "# Shade the rejection regions\n",
        "x_reject_lower = np.linspace(-4, z_critical_lower, 50)\n",
        "plt.fill_between(x_reject_lower, norm.pdf(x_reject_lower, 0, 1), color='green', alpha=0.2, label='Rejection Region')\n",
        "x_reject_upper = np.linspace(z_critical_upper, 4, 50)\n",
        "plt.fill_between(x_reject_upper, norm.pdf(x_reject_upper, 0, 1), color='green', alpha=0.2)\n",
        "\n",
        "plt.xlabel('Z-score')\n",
        "plt.ylabel('Density')\n",
        "plt.title('One-Sample Z-Test Visualization')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-nan_saiK7sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4  Perform a two-tailed Z-test using Python and visualize the decision region on a plot\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Define parameters for the Z-test\n",
        "mu = 75  # Hypothesized population mean (H0)\n",
        "sigma = 12 # Known population standard deviation (required for Z-test)\n",
        "sample_size = 100 # Size of the sample\n",
        "# Simulate a sample mean - let's make it slightly different from the hypothesized mean\n",
        "sample_mean = np.random.normal(loc=77, scale=sigma/np.sqrt(sample_size), size=1)[0]\n",
        "\n",
        "# Calculate the Z-statistic\n",
        "z_statistic = (sample_mean - mu) / (sigma / np.sqrt(sample_size))\n",
        "\n",
        "# Define the significance level (alpha) for a two-tailed test\n",
        "alpha = 0.05\n",
        "\n",
        "# Find the critical Z-values for the decision region\n",
        "# For a two-tailed test, the critical values are Z(α/2) and Z(1 - α/2)\n",
        "z_critical_lower = norm.ppf(alpha / 2)\n",
        "z_critical_upper = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "print(f\"Hypothesized Population Mean (μ₀): {mu}\")\n",
        "print(f\"Known Population Standard Deviation (σ): {sigma}\")\n",
        "print(f\"Sample Size (n): {sample_size}\")\n",
        "print(f\"Simulated Sample Mean (x̄): {sample_mean:.4f}\")\n",
        "print(f\"Calculated Z-statistic: {z_statistic:.4f}\")\n",
        "print(f\"Significance Level (α): {alpha}\")\n",
        "print(f\"Critical Z-values: ({z_critical_lower:.4f}, {z_critical_upper:.4f})\")\n",
        "\n",
        "# Calculate the P-value (for interpretation)\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_statistic)))\n",
        "print(f\"P-value (two-tailed): {p_value:.4f}\")\n",
        "\n",
        "# Make a decision based on the Z-statistic and critical values\n",
        "print(\"\\nDecision:\")\n",
        "if z_statistic < z_critical_lower or z_statistic > z_critical_upper:\n",
        "  print(f\"The calculated Z-statistic ({z_statistic:.4f}) falls within the rejection region.\")\n",
        "  print(\"Reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is sufficient evidence at the {alpha} significance level to conclude that the true population mean is significantly different from {mu}.\")\n",
        "else:\n",
        "  print(f\"The calculated Z-statistic ({z_statistic:.4f}) falls outside the rejection region.\")\n",
        "  print(\"Fail to reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is not enough evidence at the {alpha} significance level to conclude that the true population mean is significantly different from {mu}.\")\n",
        "\n",
        "# Visualize the decision region on a plot (Standard Normal Distribution)\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the standard normal distribution PDF\n",
        "x = np.linspace(-4, 4, 200)\n",
        "pdf_values = norm.pdf(x, 0, 1)\n",
        "plt.plot(x, pdf_values, label='Standard Normal Distribution (μ=0, σ=1)', color='blue')\n",
        "\n",
        "# Mark the critical Z-values and shade the rejection region\n",
        "x_reject_lower = np.linspace(-4, z_critical_lower, 50)\n",
        "plt.fill_between(x_reject_lower, norm.pdf(x_reject_lower, 0, 1), color='red', alpha=0.3, label=f'Rejection Region (α/2)')\n",
        "\n",
        "x_reject_upper = np.linspace(z_critical_upper, 4, 50)\n",
        "plt.fill_between(x_reject_upper, norm.pdf(x_reject_upper, 0, 1), color='red', alpha=0.3)\n",
        "\n",
        "plt.axvline(z_critical_lower, color='red', linestyle='--', linewidth=1.5)\n",
        "plt.axvline(z_critical_upper, color='red', linestyle='--', linewidth=1.5)\n",
        "\n",
        "# Mark the calculated Z-statistic\n",
        "plt.axvline(z_statistic, color='green', linestyle='-', linewidth=2, label=f'Calculated Z-statistic = {z_statistic:.4f}')\n",
        "\n",
        "# Mark the non-rejection region\n",
        "x_non_reject = np.linspace(z_critical_lower, z_critical_upper, 100)\n",
        "plt.fill_between(x_non_reject, norm.pdf(x_non_reject, 0, 1), color='green', alpha=0.1, label='Non-Rejection Region')\n",
        "\n",
        "plt.xlabel('Z-score')\n",
        "plt.ylabel('Density')\n",
        "plt.title(f'Two-tailed Z-Test: Decision Region (α={alpha})')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XDIjf0xqLKGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def visualize_type1_type2_errors(mu_null, sigma, sample_size, alpha, mu_alt=None):\n",
        "    \"\"\"\n",
        "    Calculates and visualizes Type 1 and Type 2 errors for a one-sample Z-test.\n",
        "\n",
        "    Args:\n",
        "        mu_null: The hypothesized population mean under the null hypothesis (H0).\n",
        "        sigma: The known population standard deviation.\n",
        "        sample_size: The size of the sample.\n",
        "        alpha: The significance level (probability of Type 1 error).\n",
        "        mu_alt: The true population mean under the alternative hypothesis (Ha).\n",
        "                If None, only Type 1 error visualization is shown.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the standard error of the mean (SEM)\n",
        "    sem = sigma / np.sqrt(sample_size)\n",
        "\n",
        "    # Calculate the critical Z-values for the decision rule\n",
        "    # For a two-tailed test, the critical values are Z(alpha/2) and Z(1 - alpha/2)\n",
        "    z_critical_lower = norm.ppf(alpha / 2)\n",
        "    z_critical_upper = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    # Convert Z-critical values back to sample means\n",
        "    # Critical sample mean lower = mu_null + Z(alpha/2) * sem\n",
        "    # Critical sample mean upper = mu_null + Z(1 - alpha/2) * sem\n",
        "    critical_mean_lower = mu_null + z_critical_lower * sem\n",
        "    critical_mean_upper = mu_null + z_critical_upper * sem\n",
        "\n",
        "    print(f\"Hypothesized Population Mean (μ₀): {mu_null}\")\n",
        "    print(f\"Known Population Standard Deviation (σ): {sigma}\")\n",
        "    print(f\"Sample Size (n): {sample_size}\")\n",
        "    print(f\"Significance Level (α): {alpha}\")\n",
        "    print(f\"Standard Error of the Mean (SEM): {sem:.4f}\")\n",
        "    print(f\"Critical Z-values: ({z_critical_lower:.4f}, {z_critical_upper:.4f})\")\n",
        "    print(f\"Critical Sample Means: ({critical_mean_lower:.4f}, {critical_mean_upper:.4f})\")\n",
        "\n",
        "    # --- Visualization of Type 1 Error ---\n",
        "    plt.figure(figsize=(12, 7))\n",
        "\n",
        "    # Plot the distribution under the null hypothesis (H0)\n",
        "    # This distribution is for the sample mean, centered at mu_null with standard deviation SEM\n",
        "    x = np.linspace(mu_null - 4 * sem, mu_null + 4 * sem, 200)\n",
        "    pdf_h0 = norm.pdf(x, mu_null, sem)\n",
        "    plt.plot(x, pdf_h0, label=f'Distribution under H₀ (μ={mu_null}, σ={sem:.4f})', color='blue')\n",
        "\n",
        "    # Shade the Type 1 Error region (alpha)\n",
        "    # This is the rejection region under the assumption that H0 is true.\n",
        "    x_type1_lower = np.linspace(mu_null - 4 * sem, critical_mean_lower, 50)\n",
        "    plt.fill_between(x_type1_lower, norm.pdf(x_type1_lower, mu_null, sem), color='red', alpha=0.3, label=f'Type 1 Error (α/2 = {alpha/2:.4f})')\n",
        "\n",
        "    x_type1_upper = np.linspace(critical_mean_upper, mu_null + 4 * sem, 50)\n",
        "    plt.fill_between(x_type1_upper, norm.pdf(x_type1_upper, mu_null, sem), color='red', alpha=0.3)\n",
        "\n",
        "    # Mark critical values\n",
        "    plt.axvline(critical_mean_lower, color='red', linestyle='--', linewidth=1.5, label=f'Critical Values')\n",
        "    plt.axvline(critical_mean_upper, color='red', linestyle='--', linewidth=1.5)\n",
        "\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Density')\n",
        "    plt.title(f'Type 1 Error (α) Visualization (Distribution under H₀)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # --- Visualization of Type 2 Error (if mu_alt is provided) ---\n",
        "    if mu_alt is not None:\n",
        "        print(f\"\\nTrue Population Mean (under Hₐ): {mu_alt}\")\n",
        "\n",
        "        # Plot the distribution under the alternative hypothesis (Ha)\n",
        "        # This distribution is for the sample mean, centered at mu_alt with standard deviation SEM\n",
        "        plt.figure(figsize=(12, 7))\n",
        "\n",
        "        x_alt = np.linspace(min(mu_null, mu_alt) - 4 * sem, max(mu_null, mu_alt) + 4 * sem, 200)\n",
        "        pdf_h0_for_overlap = norm.pdf(x_alt, mu_null, sem)\n",
        "        plt.plot(x_alt, pdf_h0_for_overlap, label=f'Distribution under H₀ (μ={mu_null})', color='blue', linestyle='--')\n",
        "\n",
        "        pdf_ha = norm.pdf(x_alt, mu_alt, sem)\n",
        "        plt.plot(x_alt, pdf_ha, label=f'Distribution under Hₐ (μ={mu_alt}, σ={sem:.4f})', color='green')\n",
        "\n",
        "        # Mark critical values again on this plot\n",
        "        plt.axvline(critical_mean_lower, color='red', linestyle='--', linewidth=1.5, label=f'Critical Values ({critical_mean_lower:.4f}, {critical_mean_upper:.4f})')\n",
        "        plt.axvline(critical_mean_upper, color='red', linestyle='--', linewidth=1.5)\n",
        "\n",
        "\n",
        "        # Shade the Type 2 Error region (Beta)\n",
        "        # This is the non-rejection region under the assumption that Ha is true.\n",
        "        # It's the area of the Ha distribution that falls within the acceptance region of H0.\n",
        "        x_type2 = np.linspace(critical_mean_lower, critical_mean_upper, 100)\n",
        "        plt.fill_between(x_type2, norm.pdf(x_type2, mu_alt, sem), color='orange', alpha=0.5, label='Type 2 Error (β)')\n",
        "\n",
        "        # Calculate the probability of Type 2 Error (Beta)\n",
        "        # Beta = P(Fail to reject H0 | H0 is False)\n",
        "        # Beta = P(Critical Mean Lower <= Sample Mean <= Critical Mean Upper | True Mean is mu_alt)\n",
        "        # Using CDF of the distribution under Ha: P(X <= critical_upper) - P(X <= critical_lower)\n",
        "        beta = norm.cdf(critical_mean_upper, loc=mu_alt, scale=sem) - norm.cdf(critical_mean_lower, loc=mu_alt, scale=sem)\n",
        "\n",
        "        print(f\"Calculated Type 2 Error (β): {beta:.4f}\")\n",
        "        print(f\"Statistical Power (1 - β): {1 - beta:.4f}\")\n",
        "        plt.text(np.mean([critical_mean_lower, critical_mean_upper]), pdf_ha.max() * 0.8, f'β = {beta:.4f}', ha='center', color='black', fontsize=10)\n",
        "\n",
        "        plt.xlabel('Sample Mean')\n",
        "        plt.ylabel('Density')\n",
        "        plt.title(f'Type 2 Error (β) Visualization (Distribution under Hₐ = {mu_alt})')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "      print(\"\\nmu_alt not provided, skipping Type 2 error visualization.\")\n",
        "\n",
        "\n",
        "# Example Usage:\n",
        "# Scenario 1: Visualize Type 1 error only\n",
        "visualize_type1_type2_errors(mu_null=70, sigma=10, sample_size=30, alpha=0.05)\n",
        "\n",
        "# Scenario 2: Visualize Type 1 and Type 2 errors with a specific alternative mean\n",
        "visualize_type1_type2_errors(mu_null=70, sigma=10, sample_size=30, alpha=0.05, mu_alt=75)\n",
        "\n",
        "# Scenario 3: Another example with different parameters\n",
        "visualize_type1_type2_errors(mu_null=50, sigma=5, sample_size=50, alpha=0.01, mu_alt=51)\n"
      ],
      "metadata": {
        "id": "UOzdWSJnLURk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6 Write a Python program to perform an independent T-test and interpret the results\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Task: Write a Python program to perform an independent T-test and interpret the results\n",
        "\n",
        "# Assume we have two independent samples representing two groups.\n",
        "# For example, test scores of students who used Method A vs. Method B.\n",
        "\n",
        "# Sample data for Group A\n",
        "group_a_scores = np.array([85, 88, 90, 82, 87, 89, 86, 84, 91, 83])\n",
        "\n",
        "# Sample data for Group B\n",
        "group_b_scores = np.array([78, 80, 83, 76, 81, 84, 79, 82, 85, 77])\n",
        "\n",
        "print(f\"Scores for Group A: {group_a_scores}\")\n",
        "print(f\"Scores for Group B: {group_b_scores}\")\n",
        "\n",
        "# Perform the independent T-test\n",
        "# Null Hypothesis (H₀): The true means of the two groups are equal (μ₁ = μ₂).\n",
        "# Alternative Hypothesis (Hₐ): The true means of the two groups are not equal (μ₁ ≠ μ₂). (Two-tailed test)\n",
        "\n",
        "# We use scipy.stats.ttest_ind for independent samples T-test.\n",
        "# The function returns the T-statistic and the p-value.\n",
        "# By default, it assumes equal variances (pooled standard deviation).\n",
        "# If you suspect unequal variances, you can set `equal_var=False` (Welch's T-test).\n",
        "t_statistic, p_value = stats.ttest_ind(group_a_scores, group_b_scores)\n",
        "\n",
        "# Define the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"\\nIndependent Samples T-Test Results:\")\n",
        "print(f\"T-statistic: {t_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Significance Level (alpha): {alpha}\")\n",
        "\n",
        "# Make a decision based on the p-value\n",
        "if p_value < alpha:\n",
        "  print(\"\\nDecision: Reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is sufficient statistical evidence at the {alpha} significance level to conclude that the true mean scores of Group A and Group B are significantly different.\")\n",
        "else:\n",
        "  print(\"\\nDecision: Fail to reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is not enough statistical evidence at the {alpha} significance level to conclude that the true mean scores of Group A and Group B are significantly different.\")\n",
        "\n",
        "# Interpretation in context\n",
        "print(\"\\nInterpretation:\")\n",
        "mean_a = np.mean(group_a_scores)\n",
        "mean_b = np.mean(group_b_scores)\n",
        "print(f\"Mean score for Group A: {mean_a:.2f}\")\n",
        "print(f\"Mean score for Group B: {mean_b:.2f}\")\n",
        "print(f\"Difference in Sample Means: {mean_a - mean_b:.2f}\")\n",
        "\n",
        "print(f\"\\nThe T-statistic ({t_statistic:.4f}) measures the difference between the two group means relative to the variability within the groups.\")\n",
        "print(f\"The P-value ({p_value:.4f}) tells us the probability of observing a T-statistic as extreme as or more extreme than {t_statistic:.4f}, assuming the null hypothesis (that there is no true difference in means) is true.\")\n",
        "\n",
        "if p_value < alpha:\n",
        "  print(f\"Since the P-value ({p_value:.4f}) is less than the significance level ({alpha}), we have strong evidence against the null hypothesis.\")\n",
        "  print(\"We conclude that the observed difference in sample means is statistically significant, suggesting a real difference between the population means of the two groups.\")\n",
        "else:\n",
        "  print(f\"Since the P-value ({p_value:.4f}) is greater than the significance level ({alpha}), we do not have enough evidence to reject the null hypothesis.\")\n",
        "  print(\"The observed difference in sample means could reasonably occur by chance if the true population means were equal.\")\n",
        "\n",
        "# Optional: Visualize the distributions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(group_a_scores, bins=5, density=True, alpha=0.6, color='skyblue', label='Group A')\n",
        "plt.hist(group_b_scores, bins=5, density=True, alpha=0.6, color='lightgreen', label='Group B')\n",
        "plt.axvline(mean_a, color='blue', linestyle='dashed', linewidth=2, label=f'Mean A: {mean_a:.2f}')\n",
        "plt.axvline(mean_b, color='green', linestyle='dashed', linewidth=2, label=f'Mean B: {mean_b:.2f}')\n",
        "plt.xlabel('Scores')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Distribution of Scores for Group A and Group B')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UwjeYO4HLe-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7  Perform a paired sample T-test using Python and visualize the comparison results\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Task: Perform a paired sample T-test using Python and visualize the comparison results\n",
        "\n",
        "# A paired sample T-test is used when the observations in the two samples are related\n",
        "# or dependent. This typically occurs when the same subjects are measured twice\n",
        "# (e.g., before and after an intervention) or when comparing paired individuals\n",
        "# (e.g., matched pairs in a study).\n",
        "\n",
        "# Assume we have data from 15 individuals on their performance score before and after\n",
        "# participating in a training program.\n",
        "\n",
        "# Performance scores Before the training\n",
        "scores_before = np.array([75, 80, 88, 72, 79, 85, 76, 81, 90, 78, 82, 87, 74, 83, 89])\n",
        "\n",
        "# Performance scores After the training for the same individuals\n",
        "scores_after = np.array([78, 83, 92, 75, 82, 88, 79, 84, 94, 81, 85, 90, 77, 86, 91])\n",
        "\n",
        "print(f\"Scores Before Training: {scores_before}\")\n",
        "print(f\"Scores After Training:  {scores_after}\")\n",
        "\n",
        "# Perform the paired sample T-test\n",
        "# Null Hypothesis (H₀): The true mean difference between the paired observations is zero (μ_diff = 0).\n",
        "# Alternative Hypothesis (Hₐ): The true mean difference is not zero (μ_diff ≠ 0). (Two-tailed test)\n",
        "\n",
        "# We use scipy.stats.ttest_rel for paired (related) samples T-test.\n",
        "# The function calculates the differences between the pairs and performs a one-sample T-test on the differences.\n",
        "# It returns the T-statistic and the p-value.\n",
        "t_statistic_paired, p_value_paired = stats.ttest_rel(scores_before, scores_after)\n",
        "\n",
        "# Define the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"\\nPaired Samples T-Test Results:\")\n",
        "print(f\"T-statistic: {t_statistic_paired:.4f}\")\n",
        "print(f\"P-value: {p_value_paired:.4f}\")\n",
        "print(f\"Significance Level (alpha): {alpha}\")\n",
        "\n",
        "# Make a decision based on the p-value\n",
        "if p_value_paired < alpha:\n",
        "  print(\"\\nDecision: Reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is sufficient statistical evidence at the {alpha} significance level to conclude that there is a significant difference between the 'Before' and 'After' scores (the training program had a significant effect).\")\n",
        "else:\n",
        "  print(\"\\nDecision: Fail to reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is not enough statistical evidence at the {alpha} significance level to conclude that there is a significant difference between the 'Before' and 'After' scores (the training program did not have a significant effect).\")\n",
        "\n",
        "# Interpretation in context\n",
        "print(\"\\nInterpretation:\")\n",
        "mean_before = np.mean(scores_before)\n",
        "mean_after = np.mean(scores_after)\n",
        "mean_difference = np.mean(scores_after - scores_before) # Mean of the differences\n",
        "\n",
        "print(f\"Mean score Before: {mean_before:.2f}\")\n",
        "print(f\"Mean score After:  {mean_after:.2f}\")\n",
        "print(f\"Mean Difference (After - Before): {mean_difference:.2f}\")\n",
        "\n",
        "print(f\"\\nThe T-statistic ({t_statistic_paired:.4f}) measures how many standard errors the mean difference ({mean_difference:.2f}) is away from zero (the value hypothesized under H₀).\")\n",
        "print(f\"The P-value ({p_value_paired:.4f}) is the probability of observing a mean difference as extreme as or more extreme than {mean_difference:.2f} if the true mean difference in the population were actually zero.\")\n",
        "\n",
        "if p_value_paired < alpha:\n",
        "  print(f\"Since the P-value ({p_value_paired:.4f}) is less than the significance level ({alpha}), we have strong evidence against the null hypothesis.\")\n",
        "  print(\"We conclude that the observed mean difference is statistically significant, suggesting that the training program led to a real change in performance.\")\n",
        "else:\n",
        "  print(f\"Since the P-value ({p_value_paired:.4f}) is greater than the significance level ({alpha}), we do not have enough evidence to reject the null hypothesis.\")\n",
        "  print(\"The observed mean difference could reasonably occur by chance if the training program had no real effect on performance.\")\n",
        "\n",
        "# Visualize the comparison results\n",
        "\n",
        "# Option 1: Box plots to show the distribution of scores before and after\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot([scores_before, scores_after], labels=['Before Training', 'After Training'], patch_artist=True,\n",
        "            boxprops=dict(facecolor='skyblue'),\n",
        "            medianprops=dict(color='red', linewidth=2))\n",
        "plt.ylabel('Performance Score')\n",
        "plt.title('Comparison of Performance Scores Before and After Training (Box Plot)')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Option 2: Histogram of the differences between scores\n",
        "differences = scores_after - scores_before\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(differences, bins=5, edgecolor='black', alpha=0.7, color='lightcoral')\n",
        "plt.axvline(np.mean(differences), color='red', linestyle='dashed', linewidth=2, label=f'Mean Difference: {np.mean(differences):.2f}')\n",
        "plt.xlabel('Difference in Score (After - Before)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Differences in Performance Scores')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Option 3: Paired plot (connecting individual scores) - Useful for showing individual changes\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(len(scores_before)):\n",
        "    plt.plot([1, 2], [scores_before[i], scores_after[i]], marker='o', color='gray', linestyle='-', alpha=0.5)\n",
        "plt.plot([1, 2], [np.mean(scores_before), np.mean(scores_after)], marker='o', color='blue', linestyle='-', linewidth=3, label='Mean Change') # Plot mean change\n",
        "plt.xticks([1, 2], ['Before Training', 'After Training'])\n",
        "plt.ylabel('Performance Score')\n",
        "plt.title('Individual and Mean Performance Score Changes Before vs. After Training')\n",
        "plt.xlim(0.8, 2.2) # Adjust limits to space out points\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QV4dp-f_LrEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8 Simulate data and perform both Z-test and T-test, then compare the results using Python\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Task: Simulate data and perform both Z-test and T-test, then compare the results using Python\n",
        "\n",
        "# This task involves demonstrating both Z-tests and T-tests and highlighting when each is appropriate\n",
        "# and how their results might compare.\n",
        "\n",
        "# --- Scenario Setup ---\n",
        "# We will simulate data under two main scenarios to illustrate Z-test and T-test conditions:\n",
        "\n",
        "# Scenario A: Conditions favoring a Z-test (Large sample size and/or known population standard deviation)\n",
        "# Scenario B: Conditions favoring a T-test (Small sample size and unknown population standard deviation)\n",
        "\n",
        "# Let's hypothesize a population mean (μ₀) that we will test against.\n",
        "hypothesized_population_mean = 100 # H₀: μ = 100\n",
        "\n",
        "# Let's assume a true (but often unknown in real scenarios) population standard deviation (σ).\n",
        "# For Scenario A (Z-test), we'll pretend we know this value.\n",
        "# For Scenario B (T-test), we'll treat it as unknown and use the sample standard deviation.\n",
        "true_population_std_dev = 15\n",
        "\n",
        "# Let's assume a true population mean (μ_true) which might be different from μ₀.\n",
        "# This allows us to see how the tests perform when H₀ is false.\n",
        "true_population_mean = 105 # Let's assume the true mean is slightly higher than H₀\n",
        "\n",
        "# Define significance level\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"Hypothesized Population Mean (H₀): μ₀ = {hypothesized_population_mean}\")\n",
        "print(f\"True Population Mean (for simulation): μ_true = {true_population_mean}\")\n",
        "print(f\"True Population Standard Deviation: σ = {true_population_std_dev}\")\n",
        "print(f\"Significance Level: α = {alpha}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- Scenario A: Large Sample (Z-test is appropriate) ---\n",
        "print(\"--- Scenario A: Large Sample Z-test ---\")\n",
        "large_sample_size = 100\n",
        "\n",
        "# Simulate a large sample from the population with the true mean and std dev\n",
        "np.random.seed(42) # for reproducibility\n",
        "large_sample_data = np.random.normal(loc=true_population_mean, scale=true_population_std_dev, size=large_sample_size)\n",
        "\n",
        "# Calculate sample statistics for the large sample\n",
        "large_sample_mean = np.mean(large_sample_data)\n",
        "large_sample_std = np.std(large_sample_data, ddof=1) # Use ddof=1 for sample std dev\n",
        "\n",
        "print(f\"Large Sample Size: {large_sample_size}\")\n",
        "print(f\"Large Sample Mean: {large_sample_mean:.4f}\")\n",
        "print(f\"Large Sample Std Dev: {large_sample_std:.4f}\")\n",
        "\n",
        "# Perform Z-test using the large sample mean, hypothesized population mean,\n",
        "# and the KNOWN true population standard deviation.\n",
        "# Z = (sample_mean - μ₀) / (σ / √n)\n",
        "sem_large = true_population_std_dev / np.sqrt(large_sample_size)\n",
        "z_statistic_large = (large_sample_mean - hypothesized_population_mean) / sem_large\n",
        "\n",
        "# Calculate p-value for the two-tailed Z-test\n",
        "p_value_z_large = 2 * (1 - norm.cdf(abs(z_statistic_large)))\n",
        "\n",
        "print(f\"\\nZ-Test Results (Large Sample, Known σ):\")\n",
        "print(f\"Calculated Z-statistic: {z_statistic_large:.4f}\")\n",
        "print(f\"P-value: {p_value_z_large:.4f}\")\n",
        "\n",
        "# Decision for Z-test (Large Sample)\n",
        "print(\"Decision:\")\n",
        "if p_value_z_large < alpha:\n",
        "    print(\"Reject H₀: The population mean is significantly different from\", hypothesized_population_mean)\n",
        "else:\n",
        "    print(\"Fail to Reject H₀: There is not enough evidence to say the population mean is different from\", hypothesized_population_mean)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# --- Scenario B: Small Sample (T-test is appropriate) ---\n",
        "print(\"--- Scenario B: Small Sample T-test ---\")\n",
        "small_sample_size = 20\n",
        "\n",
        "# Simulate a small sample from the population with the true mean and std dev\n",
        "np.random.seed(43) # use a different seed\n",
        "small_sample_data = np.random.normal(loc=true_population_mean, scale=true_population_std_dev, size=small_sample_size)\n",
        "\n",
        "# Calculate sample statistics for the small sample\n",
        "small_sample_mean = np.mean(small_sample_data)\n",
        "small_sample_std = np.std(small_sample_data, ddof=1) # Use ddof=1 for sample std dev\n",
        "\n",
        "print(f\"Small Sample Size: {small_sample_size}\")\n",
        "print(f\"Small Sample Mean: {small_sample_mean:.4f}\")\n",
        "print(f\"Small Sample Std Dev: {small_sample_std:.4f}\")\n",
        "# Note: In a real T-test scenario, we don't know the population std dev (σ).\n",
        "# We use the sample std dev (small_sample_std) as an estimate.\n",
        "\n",
        "# Perform one-sample T-test using the small sample data and hypothesized population mean.\n",
        "# This test uses the sample standard deviation and the t-distribution.\n",
        "# T = (sample_mean - μ₀) / (sample_std / √n)\n",
        "t_statistic_small, p_value_t_small = stats.ttest_1samp(small_sample_data, hypothesized_population_mean)\n",
        "\n",
        "print(f\"\\nT-Test Results (Small Sample, Unknown σ - uses sample std dev):\")\n",
        "print(f\"Calculated T-statistic: {t_statistic_small:.4f}\")\n",
        "print(f\"P-value: {p_value_t_small:.4f}\")\n",
        "print(f\"Degrees of Freedom: {small_sample_size - 1}\")\n",
        "\n",
        "# Decision for T-test (Small Sample)\n",
        "print(\"Decision:\")\n",
        "if p_value_t_small < alpha:\n",
        "    print(\"Reject H₀: The population mean is significantly different from\", hypothesized_population_mean)\n",
        "else:\n",
        "    print(\"Fail to Reject H₀: There is not enough evidence to say the population mean is different from\", hypothesized_population_mean)\n",
        "print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# --- Comparison of Results ---\n",
        "print(\"\\n--- Comparison ---\")\n",
        "print(f\"Hypothesized Population Mean (H₀): {hypothesized_population_mean}\")\n",
        "print(f\"True Population Mean (for simulation): {true_population_mean}\")\n",
        "print(f\"Significance Level (α): {alpha}\")\n",
        "print(\"\\nZ-Test (Large Sample, Known σ):\")\n",
        "print(f\"  Sample Mean: {large_sample_mean:.4f}\")\n",
        "print(f\"  Z-statistic: {z_statistic_large:.4f}\")\n",
        "print(f\"  P-value: {p_value_z_large:.4f}\")\n",
        "print(f\"  Decision: {'Reject H₀' if p_value_z_large < alpha else 'Fail to Reject H₀'}\")\n",
        "\n",
        "print(\"\\nT-Test (Small Sample, Unknown σ - uses sample std dev):\")\n",
        "print(f\"  Sample Mean: {small_sample_mean:.4f}\")\n",
        "print(f\"  T-statistic: {t_statistic_small:.4f}\")\n",
        "print(f\"  P-value: {p_value_t_small:.4f}\")\n",
        "print(f\"  Decision: {'Reject H₀' if p_value_t_small < alpha else 'Fail to Reject H₀'}\")\n",
        "\n",
        "\n",
        "# --- Explanation of Comparison ---\n",
        "print(\"\\n--- Key Differences and Why ---\")\n",
        "print(\"1.  Assumptions:\")\n",
        "print(\"    - Z-test assumes population standard deviation (σ) is KNOWN.\")\n",
        "print(\"    - T-test assumes population standard deviation (σ) is UNKNOWN and uses the SAMPLE standard deviation as an estimate.\")\n",
        "print(\"2.  Distribution:\")\n",
        "print(\"    - Z-test uses the Standard Normal Distribution.\")\n",
        "print(\"    - T-test uses the T-distribution, which has heavier tails, especially for smaller sample sizes.\")\n",
        "print(\"3.  Sample Size:\")\n",
        "print(\"    - Z-test is appropriate for large sample sizes (n > 30 is a common rule of thumb, though depends on how well the sample std dev approximates population std dev).\")\n",
        "print(\"    - T-test is necessary for small sample sizes when σ is unknown.\")\n",
        "print(\"    - As sample size increases, the T-distribution approaches the Normal Distribution, and the T-test results converge towards the Z-test results.\")\n",
        "\n",
        "print(\"\\nIn this simulation:\")\n",
        "print(f\"- Our true population mean ({true_population_mean}) is indeed different from the hypothesized mean ({hypothesized_population_mean}).\")\n",
        "# Check if H0 was correctly rejected\n",
        "if p_value_z_large < alpha:\n",
        "    print(f\"- The Z-test with a large sample ({large_sample_size}) correctly rejected H₀ (P-value={p_value_z_large:.4f}). With a large sample, the sample mean is a good estimate of the true mean, and the test had high power.\")\n",
        "else:\n",
        "     print(f\"- The Z-test with a large sample ({large_sample_size}) failed to reject H₀ (P-value={p_value_z_large:.4f}). This might happen due to sampling variability, even if H₀ is false, especially if the true mean is only slightly different.\")\n",
        "\n",
        "if p_value_t_small < alpha:\n",
        "    print(f\"- The T-test with a small sample ({small_sample_size}) also rejected H₀ (P-value={p_value_t_small:.4f}). Even with a smaller sample, the observed difference was significant enough.\")\n",
        "else:\n",
        "    print(f\"- The T-test with a small sample ({small_sample_size}) failed to reject H₀ (P-value={p_value_t_small:.4f}). This is more likely with a small sample because the test has less power to detect a difference compared to a large sample Z-test, due to higher variability in the sample mean and std dev.\")\n",
        "\n",
        "print(\"\\nNotice that the T-test P-value might be higher (less significant) than the Z-test P-value even with similar effect sizes, because the T-distribution accounts for the additional uncertainty from estimating the standard deviation from a small sample.\")\n",
        "\n",
        "# Optional: Visualize the distributions of the test statistics\n",
        "# This requires plotting the standard normal and the appropriate t-distribution\n",
        "# along with the calculated statistics and critical values.\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot Standard Normal Distribution (for Z-test)\n",
        "x_norm = np.linspace(-4, 4, 200)\n",
        "plt.plot(x_norm, norm.pdf(x_norm, 0, 1), label='Standard Normal Distribution (Z-test)', color='blue')\n",
        "z_critical_lower = norm.ppf(alpha/2)\n",
        "z_critical_upper = norm.ppf(1-alpha/2)\n",
        "plt.axvline(z_critical_lower, color='blue', linestyle='dotted', linewidth=1.5)\n",
        "plt.axvline(z_critical_upper, color='blue', linestyle='dotted', linewidth=1.5, label=f'Z Critical (α={alpha})')\n",
        "plt.axvline(z_statistic_large, color='darkblue', linestyle='--', linewidth=2, label=f'Z-statistic ({z_statistic_large:.2f})')\n",
        "\n",
        "\n",
        "# Plot T-Distribution (for T-test)\n",
        "df = small_sample_size - 1\n",
        "x_t = np.linspace(-4, 4, 200)\n",
        "plt.plot(x_t, stats.t.pdf(x_t, df), label=f'T-distribution (df={df})', color='red')\n",
        "t_critical_lower = stats.t.ppf(alpha/2, df)\n",
        "t_critical_upper = stats.t.ppf(1-alpha/2, df)\n",
        "plt.axvline(t_critical_lower, color='red', linestyle='dotted', linewidth=1.5)\n",
        "plt.axvline(t_critical_upper, color='red', linestyle='dotted', linewidth=1.5, label=f'T Critical (α={alpha}, df={df})')\n",
        "plt.axvline(t_statistic_small, color='darkred', linestyle='--', linewidth=2, label=f'T-statistic ({t_statistic_small:.2f})')\n",
        "\n",
        "\n",
        "plt.xlabel('Test Statistic Value')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Comparison of Z and T Distributions and Test Statistics')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.ylim(0, plt.ylim()[1] * 1.1) # Add some padding at the top\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nObservation from the plot:\")\n",
        "print(\"The T-distribution is flatter and wider than the Standard Normal Distribution, especially for low degrees of freedom (small sample size).\")\n",
        "print(\"This means that a T-statistic needs to be further from zero than a Z-statistic to reach the same level of statistical significance (same p-value) when the population standard deviation is unknown and estimated from the sample.\")\n",
        "print(\"The critical values for the T-test ({t_critical_lower:.4f}, {t_critical_upper:.4f}) are further from zero than the critical values for the Z-test ({z_critical_lower:.4f}, {z_critical_upper:.4f}).\")\n",
        "print(\"This reflects the increased uncertainty in the T-test due to estimating the population standard deviation.\")"
      ],
      "metadata": {
        "id": "gmWgzQgrMN3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9 Write a Python function to calculate the confidence interval for a sample mean and explain its significance\n",
        "\n",
        "import numpy as np\n",
        "def calculate_confidence_interval(data, confidence_level=0.95):\n",
        "  \"\"\"\n",
        "  Calculates the confidence interval for the mean of a sample.\n",
        "\n",
        "  Uses the t-distribution for smaller sample sizes or unknown population standard deviation,\n",
        "  and the z-distribution for large sample sizes (though t-distribution is generally safe).\n",
        "\n",
        "  Args:\n",
        "    data: A list or NumPy array of numerical data (the sample).\n",
        "    confidence_level: The desired confidence level (e.g., 0.95 for 95%).\n",
        "\n",
        "  Returns:\n",
        "    A tuple (lower_bound, upper_bound) representing the confidence interval,\n",
        "    or None if the data is empty or has insufficient size.\n",
        "  \"\"\"\n",
        "  if not data or len(data) < 2:\n",
        "    print(\"Error: Data must contain at least two points to calculate standard deviation.\")\n",
        "    return None\n",
        "\n",
        "  sample_mean = np.mean(data)\n",
        "  sample_std = np.std(data, ddof=1)  # Use ddof=1 for sample standard deviation\n",
        "  sample_size = len(data)\n",
        "  alpha = 1 - confidence_level\n",
        "\n",
        "  # Determine the appropriate distribution (T-distribution is generally safer\n",
        "  # when population std dev is unknown, regardless of sample size,\n",
        "  # but Z-distribution can be used for very large samples if preferred/justified).\n",
        "  # We'll use the t-distribution here as it's more universally applicable when sigma is unknown.\n",
        "  degrees_of_freedom = sample_size - 1\n",
        "\n",
        "  # Calculate the critical value from the t-distribution (for a two-tailed interval)\n",
        "  # ppf is the inverse of the CDF (percent-point function or quantile function)\n",
        "  t_critical = stats.t.ppf(1 - alpha / 2, degrees_of_freedom)\n",
        "\n",
        "  # Calculate the standard error of the mean (SEM)\n",
        "  standard_error = sample_std / np.sqrt(sample_size)\n",
        "\n",
        "  # Calculate the margin of error\n",
        "  margin_of_error = t_critical * standard_error\n",
        "\n",
        "  # Calculate the confidence interval bounds\n",
        "  confidence_interval_lower = sample_mean - margin_of_error\n",
        "  confidence_interval_upper = sample_mean + margin_of_error\n",
        "\n",
        "  return confidence_interval_lower, confidence_interval_upper, sample_mean, margin_of_error, confidence_level\n",
        "\n",
        "# Significance of Confidence Interval:\n",
        "# A confidence interval provides a range of plausible values for the true population parameter\n",
        "# (in this case, the population mean) based on a sample.\n",
        "#\n",
        "# Interpretation:\n",
        "# We are X% confident that the true population mean lies within the calculated interval.\n",
        "#\n",
        "# What it DOESN'T mean:\n",
        "# - It does NOT mean that there is an X% probability that the true population mean\n",
        "#   falls within this specific interval calculated from this one sample. The true mean is\n",
        "#   either in the interval or it isn't.\n",
        "# - It does NOT mean X% of the sample data falls within this interval.\n",
        "#\n",
        "# Significance and Use Cases:\n",
        "# 1. Estimation: Provides a range for the unknown population mean, not just a single point estimate (sample mean).\n",
        "# 2. Uncertainty Quantification: The width of the interval indicates the precision of the estimate. A wider interval suggests more uncertainty.\n",
        "# 3. Hypothesis Testing (implicit): If a hypothesized population mean falls outside the confidence interval, you would reject a two-tailed null hypothesis at the corresponding significance level (α = 1 - confidence_level). If it falls inside, you fail to reject.\n",
        "# 4. Comparison: Allows for comparing means of different groups or samples by looking at overlapping intervals.\n",
        "# 5. Decision Making: Helps in making informed decisions by providing a range of plausible values for a key parameter.\n",
        "\n",
        "# Example Usage:\n",
        "# Assume 'sample_data' is the dataset you want to create a confidence interval for.\n",
        "# This data is defined in the preceding code (from Task #16).\n",
        "# sample_data = np.array([52, 55, 58, 60, 63, 65, 67, 70, 72, 75])\n",
        "\n",
        "# If you need a new sample:\n",
        "sample_data_new = np.random.normal(loc=70, scale=10, size=25) # Simulate a new sample\n",
        "\n",
        "\n",
        "confidence_level_example = 0.95 # 95% confidence interval\n",
        "\n",
        "ci_result = calculate_confidence_interval(sample_data_new, confidence_level=confidence_level_example)\n",
        "\n",
        "if ci_result:\n",
        "  lower_bound, upper_bound, sample_mean, margin_of_error, conf_level = ci_result\n",
        "  print(f\"Sample Data (first 10): {sample_data_new[:10]}...\")\n",
        "  print(f\"Sample Size: {len(sample_data_new)}\")\n",
        "  print(f\"Sample Mean: {sample_mean:.4f}\")\n",
        "  print(f\"Confidence Level: {conf_level}\")\n",
        "  print(f\"Margin of Error: {margin_of_error:.4f}\")\n",
        "  print(f\"\\n{conf_level*100:.0f}% Confidence Interval for the Mean: ({lower_bound:.4f}, {upper_bound:.4f})\")\n",
        "\n",
        "  print(\"\\nSignificance and Interpretation:\")\n",
        "  print(f\"This {conf_level*100:.0f}% confidence interval [{lower_bound:.4f}, {upper_bound:.4f}] is an estimate of the range where the true population mean is likely to be.\")\n",
        "  print(f\"We are {conf_level*100:.0f}% confident that the true mean of the population from which this sample was drawn lies within this specific interval.\")\n",
        "  print(f\"The margin of error ({margin_of_error:.4f}) indicates the precision of our estimate; it's the maximum expected difference between our sample mean ({sample_mean:.4f}) and the true population mean with {conf_level*100:.0f}% confidence.\")\n"
      ],
      "metadata": {
        "id": "ZGadRnZCMZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 Write a Python program to calculate the margin of error for a given confidence level using sample data\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import binom\n",
        "from statsmodels.stats.weightstats import ztest\n",
        "from scipy import stats\n",
        "from scipy.stats import poisson\n",
        "\n",
        "# Task: Write a Python program to calculate the margin of error for a given confidence level using sample data\n",
        "\n",
        "def calculate_margin_of_error(data, confidence_level=0.95):\n",
        "  \"\"\"\n",
        "  Calculates the margin of error for a sample mean given a confidence level.\n",
        "\n",
        "  Uses the t-distribution, which is appropriate when the population\n",
        "  standard deviation is unknown (the usual case with sample data).\n",
        "\n",
        "  Args:\n",
        "    data: A list or NumPy array of numerical data (the sample).\n",
        "    confidence_level: The desired confidence level (e.g., 0.95 for 95%).\n",
        "\n",
        "  Returns:\n",
        "    The margin of error, or None if the data is empty or has insufficient size.\n",
        "  \"\"\"\n",
        "  if not data or len(data) < 2:\n",
        "    print(\"Error: Data must contain at least two points to calculate standard deviation.\")\n",
        "    return None\n",
        "\n",
        "  sample_mean = np.mean(data)\n",
        "  sample_std = np.std(data, ddof=1)  # Use ddof=1 for sample standard deviation (unbiased estimator)\n",
        "  sample_size = len(data)\n",
        "  alpha = 1 - confidence_level\n",
        "\n",
        "  # Determine the degrees of freedom for the t-distribution\n",
        "  degrees_of_freedom = sample_size - 1\n",
        "\n",
        "  # Find the critical t-value for a two-tailed interval\n",
        "  # stats.t.ppf(q, df) gives the quantile function (inverse of CDF)\n",
        "  t_critical = stats.t.ppf(1 - alpha / 2, degrees_of_freedom)\n",
        "\n",
        "  # Calculate the standard error of the mean (SEM)\n",
        "  standard_error = sample_std / np.sqrt(sample_size)\n",
        "\n",
        "  # Calculate the margin of error\n",
        "  margin_of_error = t_critical * standard_error\n",
        "\n",
        "  return margin_of_error, sample_mean, standard_error, confidence_level\n",
        "\n",
        "# Example Usage:\n",
        "# Assume 'sample_data' is a dataset you have.\n",
        "# Using the sample data from the preceding code (Task #16 or #25 or #3):\n",
        "sample_data_example = np.array([52, 55, 58, 60, 63, 65, 67, 70, 72, 75]) # Example data from preceding code\n",
        "\n",
        "# Or simulate some new sample data\n",
        "# sample_data_example = np.random.normal(loc=70, scale=10, size=30) # Simulate a sample\n",
        "\n",
        "desired_confidence_level = 0.95 # 95% confidence\n",
        "\n",
        "moe_result = calculate_margin_of_error(sample_data_example, confidence_level=desired_confidence_level)\n",
        "\n",
        "if moe_result:\n",
        "  margin_of_error, sample_mean, standard_error, conf_level = moe_result\n",
        "  print(f\"Sample Data (first 10): {sample_data_example[:10]}...\")\n",
        "  print(f\"Sample Size: {len(sample_data_example)}\")\n",
        "  print(f\"Sample Mean: {sample_mean:.4f}\")\n",
        "  print(f\"Confidence Level: {conf_level}\")\n",
        "  print(f\"Standard Error of the Mean (SEM): {standard_error:.4f}\")\n",
        "  print(f\"Calculated Margin of Error: {margin_of_error:.4f}\")\n",
        "\n",
        "  # Calculate the corresponding confidence interval (optional, but often useful with MOE)\n",
        "  confidence_interval_lower = sample_mean - margin_of_error\n",
        "  confidence_interval_upper = sample_mean + margin_of_error\n",
        "  print(f\"\\n{conf_level*100:.0f}% Confidence Interval: ({confidence_interval_lower:.4f}, {confidence_interval_upper:.4f})\")\n",
        "\n",
        "  print(\"\\nInterpretation of Margin of Error:\")\n",
        "  print(f\"The margin of error ({margin_of_error:.4f}) tells us the maximum likely difference between our sample mean ({sample_mean:.4f}) and the true population mean for the given confidence level ({conf_level*100:.0f}%).\")\n",
        "  print(f\"With {conf_level*100:.0f}% confidence, we estimate that the true population mean is within {margin_of_error:.4f} units of our sample mean.\")\n",
        "  print(\"A smaller margin of error indicates a more precise estimate of the population mean.\")\n",
        "  print(\"Factors that influence the margin of error:\")\n",
        "  print(\"- Sample Size: Larger sample size decreases the standard error, thus decreasing the margin of error.\")\n",
        "  print(\"- Standard Deviation: Higher variability (larger standard deviation) in the data increases the standard error, thus increasing the margin of error.\")\n",
        "  print(\"- Confidence Level: A higher confidence level requires a larger critical value, thus increasing the margin of error.\")"
      ],
      "metadata": {
        "id": "OaxYUb2fMiOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11 Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import binom\n",
        "from statsmodels.stats.weightstats import ztest\n",
        "from scipy import stats\n",
        "from scipy.stats import poisson\n",
        "from scipy.special import factorial # Used in Bayes' Theorem example\n",
        "\n",
        "def bayes_theorem_example(prior_A, prior_B, likelihood_obs_given_A, likelihood_obs_given_B):\n",
        "    \"\"\"\n",
        "    Implements Bayes' Theorem to calculate the posterior probability of events.\n",
        "\n",
        "    Bayes' Theorem: P(A|Obs) = [P(Obs|A) * P(A)] / P(Obs)\n",
        "    Where P(Obs) = P(Obs|A) * P(A) + P(Obs|B) * P(B) (Law of Total Probability)\n",
        "\n",
        "    This function demonstrates a simple scenario with two mutually exclusive\n",
        "    and exhaustive events (A and B) and a single observation.\n",
        "\n",
        "    Args:\n",
        "        prior_A: The prior probability of event A occurring, P(A).\n",
        "        prior_B: The prior probability of event B occurring, P(B).\n",
        "                 Assumes A and B are mutually exclusive and exhaustive, so prior_A + prior_B should be 1.\n",
        "        likelihood_obs_given_A: The likelihood of the observation given event A, P(Obs|A).\n",
        "        likelihood_obs_given_B: The likelihood of the observation given event B, P(Obs|B).\n",
        "\n",
        "    Returns:\n",
        "        The posterior probability of event A given the observation, P(A|Obs).\n",
        "        Returns None if prior probabilities do not sum to 1.\n",
        "    \"\"\"\n",
        "    if not np.isclose(prior_A + prior_B, 1.0):\n",
        "        print(\"Error: Prior probabilities must sum to 1 for mutually exclusive and exhaustive events.\")\n",
        "        return None\n",
        "\n",
        "    # Calculate the probability of the observation (Evidence) using the Law of Total Probability\n",
        "    # P(Obs) = P(Obs|A) * P(A) + P(Obs|B) * P(B)\n",
        "    probability_observation = (likelihood_obs_given_A * prior_A) + (likelihood_obs_given_B * prior_B)\n",
        "\n",
        "    # Handle case where the observation is impossible under either event (probability_observation is 0)\n",
        "    if probability_observation == 0:\n",
        "        print(\"Error: Probability of the observation is zero. Cannot calculate posterior.\")\n",
        "        return 0 # Or handle as appropriate for the specific problem context\n",
        "\n",
        "    # Calculate the posterior probability of A given the observation using Bayes' Theorem\n",
        "    # P(A|Obs) = [P(Obs|A) * P(A)] / P(Obs)\n",
        "    posterior_A_given_obs = (likelihood_obs_given_A * prior_A) / probability_observation\n",
        "\n",
        "    return posterior_A_given_obs\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# Scenario: Medical Testing\n",
        "# Assume a disease (Event D) affects 1% of the population.\n",
        "# We have a test (Observation +) that is 95% accurate (P(+|D) = 0.95)\n",
        "# and has a 10% false positive rate (P(+|Not D) = 0.10).\n",
        "# We want to find the probability of having the disease given a positive test result (P(D|+)).\n",
        "\n",
        "# Let:\n",
        "# Event A = Having the Disease (D)\n",
        "# Event B = Not Having the Disease (Not D)\n",
        "# Observation = Positive Test Result (+)\n",
        "\n",
        "prior_D = 0.01      # P(D) - Prior probability of having the disease\n",
        "prior_Not_D = 1 - prior_D # P(Not D) - Prior probability of not having the disease\n",
        "\n",
        "likelihood_pos_given_D = 0.95 # P(+|D) - Likelihood of a positive test given the disease (Sensitivity)\n",
        "likelihood_pos_given_Not_D = 0.10 # P(+|Not D) - Likelihood of a positive test given no disease (False Positive Rate)\n",
        "\n",
        "# Now, use the function to calculate P(D|+)\n",
        "# In our function mapping: A -> D, B -> Not D, Obs -> +\n",
        "posterior_D_given_pos = bayes_theorem_example(\n",
        "    prior_A=prior_D,\n",
        "    prior_B=prior_Not_D,\n",
        "    likelihood_obs_given_A=likelihood_pos_given_D,\n",
        "    likelihood_obs_given_B=likelihood_pos_given_Not_D\n",
        ")\n",
        "\n",
        "print(\"--- Bayesian Inference Example (Medical Test) ---\")\n",
        "print(f\"Prior Probability of Disease (P(D)): {prior_D:.4f}\")\n",
        "print(f\"Prior Probability of No Disease (P(Not D)): {prior_Not_D:.4f}\")\n",
        "print(f\"Likelihood of Positive Test given Disease (P(+|D)): {likelihood_pos_given_D:.4f}\")\n",
        "print(f\"Likelihood of Positive Test given No Disease (P(+|Not D)): {likelihood_pos_given_Not_D:.4f}\")\n",
        "\n",
        "if posterior_D_given_pos is not None:\n",
        "    print(f\"\\nPosterior Probability of Disease given Positive Test (P(D|+)): {posterior_D_given_pos:.4f}\")\n",
        "\n",
        "    # Explanation of the process:\n",
        "    print(\"\\nExplanation of the Bayesian Inference Process:\")\n",
        "    print(\"1.  Start with Prior Probabilities: We have an initial belief about the probability of the events (having or not having the disease) before any new evidence is considered. P(D) and P(Not D) are our priors.\")\n",
        "    print(f\"    - Our initial belief is that the probability of having the disease is {prior_D*100:.2f}%.\")\n",
        "\n",
        "    print(\"2.  Consider the Likelihood of the Evidence: We observe new evidence (a positive test result). We need to know how likely this evidence is under each of the possible events (having or not having the disease). These are the likelihoods, P(+|D) and P(+|Not D).\")\n",
        "    print(f\"    - The test is positive. The likelihood of this positive test is {likelihood_pos_given_D*100:.2f}% if the person has the disease, and {likelihood_pos_given_Not_D*100:.2f}% if they don't.\")\n",
        "\n",
        "    print(\"3.  Calculate the Probability of the Evidence (Marginal Likelihood): We need to know the overall probability of observing the evidence (a positive test), considering all possible events. This is P(+), calculated using the Law of Total Probability:\")\n",
        "    print(\"    P(+) = P(+|D) * P(D) + P(+|Not D) * P(Not D)\")\n",
        "    # Calculate P(Obs) separately to show this step\n",
        "    probability_observation_exp = (likelihood_pos_given_D * prior_D) + (likelihood_pos_given_Not_D * prior_Not_D)\n",
        "    print(f\"    P(+) = ({likelihood_pos_given_D} * {prior_D}) + ({likelihood_pos_given_Not_D} * {prior_Not_D}) = {probability_observation_exp:.4f}\")\n",
        "    print(f\"    The overall probability of getting a positive test result in this population is {probability_observation_exp:.4f}.\")\n",
        "\n",
        "    print(\"4.  Apply Bayes' Theorem: Now we update our initial belief (prior) based on the new evidence (positive test) and the likelihoods, to get the Posterior Probability, P(D|+).\")\n",
        "    print(\"    P(D|+) = [P(+|D) * P(D)] / P(+)\")\n",
        "    print(f\"    P(D|+) = ({likelihood_pos_given_D} * {prior_D}) / {probability_observation_exp:.4f}\")\n",
        "    print(f\"    P(D|+) = {posterior_D_given_pos:.4f}\")\n",
        "\n",
        "    print(f\"\\nResult Interpretation:\")\n",
        "    print(f\"After observing a positive test result, the updated probability of having the disease (Posterior probability) is {posterior_D_given_pos:.4f}.\")\n",
        "    print(f\"This is significantly higher than the initial prior probability of {prior_D:.4f}, but it's important to note it's not 100%, even with a seemingly accurate test, because of the low prior probability of the disease and the false positive rate.\")\n",
        "\n",
        "# --- Another Simple Example ---\n",
        "# Scenario: Two Bags of Marbles\n",
        "# Bag 1 (Event A): 70% Red, 30% Blue\n",
        "# Bag 2 (Event B): 20% Red, 80% Blue\n",
        "# We randomly picked a bag (assume 50/50 chance for each bag - equal priors)\n",
        "# and drew a Red marble (Observation).\n",
        "# What is the probability that we picked Bag 1 given we drew a Red marble? P(Bag1 | Red)?\n",
        "\n",
        "prior_Bag1 = 0.5  # P(Bag1)\n",
        "prior_Bag2 = 0.5  # P(Bag2)\n",
        "\n",
        "likelihood_Red_given_Bag1 = 0.7 # P(Red | Bag1)\n",
        "likelihood_Red_given_Bag2 = 0.2 # P(Red | Bag2)\n",
        "\n",
        "# Calculate P(Bag1 | Red)\n",
        "# In our function mapping: A -> Bag1, B -> Bag2, Obs -> Red\n",
        "posterior_Bag1_given_Red = bayes_theorem_example(\n",
        "    prior_A=prior_Bag1,\n",
        "    prior_B=prior_Bag2,\n",
        "    likelihood_obs_given_A=likelihood_Red_given_Bag1,\n",
        "    likelihood_obs_given_B=likelihood_Red_given_Bag2\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"--- Bayesian Inference Example (Marble Bags) ---\")\n",
        "print(f\"Prior Probability of Bag 1 (P(Bag1)): {prior_Bag1:.4f}\")\n",
        "print(f\"Prior Probability of Bag 2 (P(Bag2)): {prior_Bag2:.4f}\")\n",
        "print(f\"Likelihood of Red given Bag 1 (P(Red|Bag1)): {likelihood_Red_given_Bag1:.4f}\")\n",
        "print(f\"Likelihood of Red given Bag 2 (P(Red|Bag2)): {likelihood_Red_given_Bag2:.4f}\")\n",
        "\n",
        "if posterior_Bag1_given_Red is not None:\n",
        "     print(f\"\\nPosterior Probability of Bag 1 given Red Marble (P(Bag1|Red)): {posterior_Bag1_given_Red:.4f}\")\n",
        "     print(f\"Posterior Probability of Bag 2 given Red Marble (P(Bag2|Red)): {1 - posterior_Bag1_given_Red:.4f}\") # Since Bag1 and Bag2 are exhaustive\n",
        "\n",
        "     # Explanation\n",
        "     print(\"\\nResult Interpretation:\")\n",
        "     print(f\"Starting with a 50/50 chance of picking either bag, observing a Red marble (which is more likely to come from Bag 1) updates our belief.\")\n",
        "     print(f\"The updated probability that we picked Bag 1, given we saw a Red marble, is {posterior_Bag1_given_Red:.4f}.\")\n",
        "     print(f\"This is higher than our initial prior probability of {prior_Bag1:.4f}, demonstrating how the evidence (the Red marble) shifted our belief towards Bag 1.\")\n",
        "```"
      ],
      "metadata": {
        "id": "GA15KEtAMuqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12 Perform a Chi-square test for independence between two categorical variables in Python\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Task: Perform a Chi-square test for independence between two categorical variables in Python\n",
        "\n",
        "# Assume we have data on two categorical variables, for example:\n",
        "# Variable 1: 'Treatment Group' (Categorical: 'Control', 'Treatment')\n",
        "# Variable 2: 'Outcome' (Categorical: 'Improvement', 'No Improvement')\n",
        "\n",
        "# The Chi-square test for independence tests the null hypothesis (H₀) that\n",
        "# there is no association between the two categorical variables in the population\n",
        "# versus the alternative hypothesis (Hₐ) that there is an association.\n",
        "\n",
        "# Let's represent the data in a contingency table (or frequency table).\n",
        "# Each cell in the table shows the count of observations that fall into\n",
        "# a specific combination of categories for the two variables.\n",
        "\n",
        "# Example Contingency Table (Counts):\n",
        "#                | Improvement | No Improvement | Row Total\n",
        "# ---------------|-------------|----------------|-----------\n",
        "# Control Group  |     40      |       60       |   100\n",
        "# Treatment Group|     70      |       30       |   100\n",
        "# ---------------|-------------|----------------|-----------\n",
        "# Column Total   |    110      |       90       |   200 (Grand Total)\n",
        "\n",
        "# We can create this table using a NumPy array or a Pandas DataFrame.\n",
        "# Using a NumPy array is straightforward for the input to chi2_contingency.\n",
        "contingency_table = np.array([\n",
        "    [40, 60],  # Row for Control Group\n",
        "    [70, 30]   # Row for Treatment Group\n",
        "])\n",
        "\n",
        "print(\"Contingency Table:\")\n",
        "# Optional: Display with labels for clarity\n",
        "contingency_df = pd.DataFrame(contingency_table,\n",
        "                              index=['Control Group', 'Treatment Group'],\n",
        "                              columns=['Improvement', 'No Improvement'])\n",
        "print(contingency_df)\n",
        "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
        "\n",
        "# Perform the Chi-square test for independence\n",
        "# scipy.stats.chi2_contingency takes the contingency table as input.\n",
        "# It returns:\n",
        "# 1. chi2: The Chi-square test statistic.\n",
        "# 2. p: The p-value of the test.\n",
        "# 3. dof: The degrees of freedom of the test.\n",
        "# 4. expected: The expected frequencies, based on the assumption of independence.\n",
        "chi2_statistic, p_value, degrees_of_freedom, expected_frequencies = chi2_contingency(contingency_table)\n",
        "\n",
        "# Define the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "print(\"Chi-square Test for Independence Results:\")\n",
        "print(f\"Chi-square Statistic: {chi2_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Degrees of Freedom: {degrees_of_freedom}\")\n",
        "print(\"\\nExpected Frequencies (assuming independence):\")\n",
        "print(pd.DataFrame(expected_frequencies, index=contingency_df.index, columns=contingency_df.columns))\n",
        "\n",
        "# Make a decision based on the p-value\n",
        "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
        "print(\"Hypothesis Test Decision:\")\n",
        "print(f\"Significance Level (alpha): {alpha}\")\n",
        "\n",
        "if p_value < alpha:\n",
        "  print(\"\\nDecision: Reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is sufficient statistical evidence at the {alpha} significance level to conclude that there is a significant association (dependence) between Treatment Group and Outcome.\")\n",
        "else:\n",
        "  print(\"\\nDecision: Fail to reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is not enough statistical evidence at the {alpha} significance level to conclude that there is a significant association (dependence) between Treatment Group and Outcome. The variables appear to be independent.\")\n",
        "\n",
        "# Interpretation in context\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"The Chi-square statistic measures the difference between the observed frequencies in the contingency table and the expected frequencies (what we would expect if the variables were independent).\")\n",
        "print(\"A larger Chi-square statistic indicates a larger difference between observed and expected counts.\")\n",
        "print(f\"The P-value ({p_value:.4f}) is the probability of observing a Chi-square statistic as extreme as, or more extreme than, {chi2_statistic:.4f}, assuming the null hypothesis of independence is true.\")\n",
        "\n",
        "if p_value < alpha:\n",
        "  print(f\"Since the P-value ({p_value:.4f}) is less than the significance level ({alpha}), we have strong evidence against the null hypothesis.\")\n",
        "  print(\"This suggests that the distribution of 'Outcome' is significantly different across the 'Treatment Groups', indicating that the treatment likely had an effect on the outcome.\")\n",
        "else:\n",
        "  print(f\"Since the P-value ({p_value:.4f}) is greater than the significance level ({alpha}), we do not have enough evidence to reject the null hypothesis.\")\n",
        "  print(\"This suggests that any observed differences in 'Outcome' between the 'Treatment Groups' could reasonably be due to random chance, assuming the treatment had no real effect on the outcome.\")\n",
        "\n",
        "# Optional: Visualize the observed vs. expected frequencies or bar plots of proportions\n",
        "# This helps to see where the differences lie.\n",
        "\n",
        "# Calculate observed and expected proportions\n",
        "observed_proportions = contingency_df.apply(lambda x: x / x.sum(), axis=1) # Row proportions\n",
        "expected_table_df = pd.DataFrame(expected_frequencies, index=contingency_df.index, columns=contingency_df.columns)\n",
        "expected_proportions = expected_table_df.apply(lambda x: x / x.sum(), axis=1) # Row proportions\n",
        "\n",
        "\n",
        "print(\"\\nObserved Row Proportions:\")\n",
        "print(observed_proportions)\n",
        "print(\"\\nExpected Row Proportions (if independent):\")\n",
        "print(expected_proportions)\n",
        "\n",
        "\n",
        "# Stacked bar plot comparing proportions\n",
        "observed_proportions.T.plot(kind='bar', stacked=True, figsize=(10, 7), color=['skyblue', 'salmon'])\n",
        "plt.title('Observed Proportions of Outcome by Treatment Group')\n",
        "plt.xlabel('Treatment Group')\n",
        "plt.ylabel('Proportion')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Outcome', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# You could also compare the observed and expected counts directly using bar plots or heatmaps of the difference."
      ],
      "metadata": {
        "id": "1uFXQyK6M_r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13 Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Task: Write a Python program to calculate the expected frequencies for a Chi-square test based on observed data\n",
        "\n",
        "# The expected frequency for a cell in a contingency table, assuming independence\n",
        "# between the row and column variables, is calculated as:\n",
        "# Expected Frequency = (Row Total * Column Total) / Grand Total\n",
        "\n",
        "# This calculation is implicitly done by the `scipy.stats.chi2_contingency` function\n",
        "# and returned as the fourth element in its output tuple.\n",
        "\n",
        "# We will reuse the contingency table defined in the preceding code snippet (Task #12).\n",
        "# This table represents observed frequencies.\n",
        "\n",
        "# Example Contingency Table (Observed Frequencies):\n",
        "#                | Improvement | No Improvement | Row Total\n",
        "# ---------------|-------------|----------------|-----------\n",
        "# Control Group  |     40      |       60       |   100\n",
        "# Treatment Group|     70      |       30       |   100\n",
        "# ---------------|-------------|----------------|-----------\n",
        "# Column Total   |    110      |       90       |   200 (Grand Total)\n",
        "\n",
        "contingency_table_observed = np.array([\n",
        "    [40, 60],  # Row for Control Group\n",
        "    [70, 30]   # Row for Treatment Group\n",
        "])\n",
        "\n",
        "print(\"Observed Frequencies (Contingency Table):\")\n",
        "contingency_df_observed = pd.DataFrame(contingency_table_observed,\n",
        "                                        index=['Control Group', 'Treatment Group'],\n",
        "                                        columns=['Improvement', 'No Improvement'])\n",
        "print(contingency_df_observed)\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# Calculate Expected Frequencies Manually (to demonstrate the formula)\n",
        "\n",
        "# Get Row Totals, Column Totals, and Grand Total\n",
        "row_totals = np.sum(contingency_table_observed, axis=1)\n",
        "column_totals = np.sum(contingency_table_observed, axis=0)\n",
        "grand_total = np.sum(contingency_table_observed)\n",
        "\n",
        "# Create an empty array for expected frequencies\n",
        "expected_frequencies_manual = np.zeros_like(contingency_table_observed, dtype=float)\n",
        "\n",
        "# Calculate expected frequency for each cell\n",
        "num_rows, num_cols = contingency_table_observed.shape\n",
        "\n",
        "for i in range(num_rows):\n",
        "  for j in range(num_cols):\n",
        "    expected_frequencies_manual[i, j] = (row_totals[i] * column_totals[j]) / grand_total\n",
        "\n",
        "print(\"Calculated Expected Frequencies (Manual):\")\n",
        "expected_df_manual = pd.DataFrame(expected_frequencies_manual,\n",
        "                                   index=contingency_df_observed.index,\n",
        "                                   columns=contingency_df_observed.columns)\n",
        "print(expected_df_manual.round(2)) # Round for display\n",
        "\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# Verify with scipy.stats.chi2_contingency\n",
        "\n",
        "# Perform the Chi-square test again just to extract the expected frequencies calculated by scipy\n",
        "# We don't need the other outputs for this specific task, but they are returned by the function.\n",
        "chi2_statistic, p_value, degrees_of_freedom, expected_frequencies_scipy = chi2_contingency(contingency_table_observed)\n",
        "\n",
        "print(\"Expected Frequencies (Calculated by scipy.stats.chi2_contingency):\")\n",
        "expected_df_scipy = pd.DataFrame(expected_frequencies_scipy,\n",
        "                                   index=contingency_df_observed.index,\n",
        "                                   columns=contingency_df_observed.columns)\n",
        "print(expected_df_scipy.round(2)) # Round for display\n",
        "\n",
        "print(\"\\nComparison:\")\n",
        "# Check if manual calculation matches scipy's output (allowing for floating point differences)\n",
        "if np.allclose(expected_frequencies_manual, expected_frequencies_scipy):\n",
        "    print(\"Manual calculation of expected frequencies matches scipy's output.\")\n",
        "else:\n",
        "    print(\"Manual calculation of expected frequencies differs from scipy's output (check logic).\")\n",
        "\n",
        "# The expected frequencies tell us what the cell counts would be if the two\n",
        "# categorical variables were perfectly independent in the population, given the\n",
        "# observed row and column totals. The Chi-square test compares the observed\n",
        "# frequencies to these expected frequencies to determine if the deviations are\n",
        "# larger than what would be expected by random chance alone.\n",
        "\n"
      ],
      "metadata": {
        "id": "F50FmCvMNI7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14 Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution\n",
        "\n",
        "# A goodness-of-fit test (like the Chi-square goodness-of-fit test) is used to determine\n",
        "# if a sample distribution matches a hypothesized theoretical distribution.\n",
        "\n",
        "# Task: Perform a goodness-of-fit test (Chi-square) using Python to compare observed\n",
        "# data (counts in categories) to expected frequencies based on a hypothesized distribution.\n",
        "\n",
        "# Scenario: Suppose we roll a standard six-sided die 600 times.\n",
        "# Hypothesized Distribution (Null Hypothesis H0): The die is fair.\n",
        "#   This means each face (1, 2, 3, 4, 5, 6) is equally likely to appear.\n",
        "#   The expected proportion for each face is 1/6.\n",
        "# Alternative Hypothesis (Ha): The die is not fair.\n",
        "\n",
        "# Observed Data: Let's say we recorded the following counts for each face:\n",
        "observed_counts = np.array([95, 105, 100, 98, 102, 100]) # Counts for faces 1 to 6\n",
        "categories = np.arange(1, 7) # The faces of the die\n",
        "\n",
        "total_observations = np.sum(observed_counts)\n",
        "print(f\"Observed Counts for each face (1-6): {observed_counts}\")\n",
        "print(f\"Total Observations: {total_observations}\")\n",
        "\n",
        "# Hypothesized Expected Distribution (under H0: Fair die)\n",
        "# The expected frequency for each category is (Total Observations * Hypothesized Proportion for Category)\n",
        "# For a fair die, the proportion for each face is 1/6.\n",
        "hypothesized_proportions = np.array([1/6, 1/6, 1/6, 1/6, 1/6, 1/6])\n",
        "\n",
        "# Calculate the expected frequencies\n",
        "expected_frequencies = total_observations * hypothesized_proportions\n",
        "print(f\"\\nHypothesized Proportions (Fair Die): {hypothesized_proportions}\")\n",
        "print(f\"Expected Frequencies (under H0): {expected_frequencies}\")\n",
        "\n",
        "# Perform the Chi-square goodness-of-fit test\n",
        "# scipy.stats.chisquare performs the test.\n",
        "# It takes the observed counts and the expected counts as input.\n",
        "# It returns the Chi-square test statistic and the p-value.\n",
        "chi2_statistic_gof, p_value_gof = stats.chisquare(f_obs=observed_counts, f_exp=expected_frequencies)\n",
        "\n",
        "# Define the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"\\nChi-square Goodness-of-Fit Test Results:\")\n",
        "print(f\"Chi-square Statistic: {chi2_statistic_gof:.4f}\")\n",
        "print(f\"P-value: {p_value_gof:.4f}\")\n",
        "# For the Chi-square goodness-of-fit test, the degrees of freedom are k - 1,\n",
        "# where k is the number of categories. In this case, k=6, so df = 6 - 1 = 5.\n",
        "degrees_of_freedom_gof = len(categories) - 1\n",
        "print(f\"Degrees of Freedom: {degrees_of_freedom_gof}\")\n",
        "\n",
        "# Make a decision based on the p-value\n",
        "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
        "print(\"Hypothesis Test Decision:\")\n",
        "print(f\"Significance Level (alpha): {alpha}\")\n",
        "\n",
        "if p_value_gof < alpha:\n",
        "  print(\"\\nDecision: Reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is sufficient statistical evidence at the {alpha} significance level to conclude that the observed distribution of die rolls is significantly different from the expected distribution of a fair die.\")\n",
        "  print(\"This suggests the die might not be fair.\")\n",
        "else:\n",
        "  print(\"\\nDecision: Fail to reject the null hypothesis (H₀).\")\n",
        "  print(f\"Conclusion: There is not enough statistical evidence at the {alpha} significance level to conclude that the observed distribution of die rolls is significantly different from the expected distribution of a fair die.\")\n",
        "  print(\"The observed differences from the expected counts could reasonably be due to random chance, assuming the die is fair.\")\n",
        "\n",
        "# Interpretation in context\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"The Chi-square goodness-of-fit test compares the observed frequencies in each category to the frequencies expected under the null hypothesis.\")\n",
        "print(\"The Chi-square statistic quantifies the overall discrepancy between the observed and expected counts.\")\n",
        "print(f\"The P-value ({p_value_gof:.4f}) is the probability of observing data that deviates from the expected distribution as much as, or more than, our observed data, assuming the hypothesized distribution (fair die) is true.\")\n",
        "\n",
        "if p_value_gof < alpha:\n",
        "  print(f\"Since the P-value ({p_value_gof:.4f}) is less than {alpha}, the observed counts are statistically unlikely if the die were truly fair. We conclude the die is biased.\")\n",
        "else:\n",
        "  print(f\"Since the P-value ({p_value_gof:.4f}) is greater than {alpha}, the observed counts are reasonably likely to occur even if the die were fair. We do not have enough evidence to conclude the die is biased.\")\n",
        "\n",
        "\n",
        "# Optional: Visualize the observed vs. expected frequencies\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(categories))\n",
        "\n",
        "plt.bar(index, observed_counts, bar_width, label='Observed Counts', color='skyblue')\n",
        "plt.bar(index + bar_width, expected_frequencies, bar_width, label='Expected Frequencies (H0)', color='lightcoral', alpha=0.7)\n",
        "\n",
        "plt.xlabel('Die Face')\n",
        "plt.ylabel('Frequency (Counts)')\n",
        "plt.title('Observed vs. Expected Frequencies of Die Rolls (Goodness-of-Fit)')\n",
        "plt.xticks(index + bar_width / 2, categories)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TZgyxdPFNau0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}